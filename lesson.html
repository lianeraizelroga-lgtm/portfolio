<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lesson Gallery Page</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <!--Navigation Header-->
    <nav id="navbar">
        <ul>
            <li><a href="#" class="left">Portfolio.</a></li>
            <li><a href="home.html" class="right">Home</a></li>
            <li><a href="skills.html" class="right">Skills</a></li>
            <li><a href="lesson.html" class="active right">Lesson Gallery</a></li>
            <li><a href="contact.html" class="right">Contact Me</a></li>
        </ul>
    </nav>

    <div id="mySidebar" class="sidebar">
        <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
        <div class="dropdown">
            <a href="#l1">üîΩLesson 1: Computing Industry</a>
            <div class="dropdown-content">
                <a href="#l1A">üîçOverview of the Computer Industry</a>
                <a href="#l1B">üîçSWOT Analysis of the Computer Industry</a>
                <a href="#l1C">üîçEvolution of the Computer Industry</a>
                <a href="#l1D">üîçEmerging Trends in the Computer Industry</a>
                <a href="#l1E">üîçGlobal Landscape of the Computer Industry</a>
                <a href="#l1F">üîçFuture Outlook for the Computer Industry</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l2">üîΩLesson 2: Computing and Other Sciences</a>
            <div class="dropdown-content">
                <a href="#l2A">üîçIntroduction to Computer Science</a>
                <a href="#l2B">üîçComputing and Formal Science</a>
                <a href="#l2C">üîçComputing and Natural Science</a>
                <a href="#l2D">üîçComputing and Social Science</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l3">üîΩLesson 3: The Computing System</a>
            <div class="dropdown-content">
                <a href="#l3A">üîçIntroduction to Computer System</a>
                <a href="#l3B">üîçComponents of a Computer System</a>
                <a href="#l3C">üîçTypes of Computer Systems</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l4">üîΩLesson 4: Number System and Binary Arithmetic</a>
            <div class="dropdown-content">
                <a href="#l4A">üîçIntroduction to Number System</a>
                <a href="#l4B">üîçTypes of Number Systems</a>
                <a href="#l4C">üîçConversion from Decimal to Other Number Systems</a>
                <a href="#l4D">üîçConversion from Other Number Systems to Decimal</a>
                <a href="#l4E">üîçArithmetic Operations of Binary Numbers</a>
                <a href="#l4F">üîçSample Problems of Binary Arithmetic</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l5">üîΩLesson 5: Digital Logic System</a>
            <div class="dropdown-content">
                <a href="#l5A">üîçIntroduction to Boolean Algebra</a>
                <a href="#l5B">üîçBoolean Algebra Table (Extended)</a>
                <a href="#l5C">üîçLaws for Boolean Algebra</a>
                <a href="#l5D">üîçDigital Electronics and Logic Design</a>
                <a href="#l5E">üîçCore Concepts and Applications</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l6">üîΩLesson 6: Electronic Media</a>
            <div class="dropdown-content">
                <a href="#l6A">üîçIntroduction to Electronic Media</a>
                <a href="#l6B">üîçHistory of Electronic Media</a>
                <a href="#l6C">üîçPrinciples of the Network & Types of Electronic Media</a>
                <a href="#l6D">üîçAdvantage and Disadvantage of Electronic Media</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l7">üîΩLesson 7: The Internet</a>
            <div class="dropdown-content">
                <a href="#l7A">üîçIntroduction to Internet</a>
                <a href="#l7B">üîçHow the Internet Works</a>
                <a href="#l7C">üîçApplications of Internet</a>
                <a href="#l7D">üîçInternet Safety and the Future</a>
            </div>
        </div>
        <div class="dropdown">
            <a href="#l8">üîΩLesson 8: Ethics in Computing Industry</a>
            <div class="dropdown-content">
                <a href="#l8A">üîçIntroduction to Ethics in Computing Industry</a>
                <a href="#l8B">üîçIntellectual Property Rights</a>
                <a href="#l8C">üîçDigital Counterfeiting</a>
            </div>
        </div>
    </div>

    <div class="space-down animate">
        <!--Header Section-->
        <header>
            <h1>Lesson Gallery</h1>
        </header>
        <!--Main Content Area-->
        <main id="main">
            <button class="dark-button" id="dark-toggle" onclick="DarkMode()">Dark Mode</button>
            <button class="openbtn" onclick="openNav()">&#9776; Lessons Sidebar</button>
            <section class="lessons"><!--LESSON 1-->
                <h2 id="l1">üë®‚ÄçüíªLesson 1: Computing Industry</h2>
                <a href="https://blog.osum.com/computer-industry-analysis/#globallandscapeofthecomputerindustry" class="source">
                    <h3>Source: Blog.osum.com</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l1A">Overview of the Computer Industry</h3>
                <p>The computer industry plays a pivotal role in driving technological advancements and shaping the modern world. This section provides an introduction to the computer industry and highlights the key players involved.</p>
                <br>
                <h3>Introduction to the Computer Industry</h3>
                <p>The computer industry encompasses a wide range of businesses involved in the development, manufacturing, and distribution of computer hardware, software, and related services. It has revolutionized various sectors, from communication and entertainment to healthcare and finance.</p>
                <p>With the ongoing development of technologies such as artificial intelligence, cloud computing, and the Internet of Things (IoT), the computer industry continues to drive innovation and shape the future of computing and technology. The convergence of these technologies has the potential to radically transform industries such as gaming, healthcare, education, and retail, offering innovative solutions and immersive experiences (Cointelegraph).</p>
                <br>
                <h3>Key Players in the Computer Industry</h3>
                <p>The computer industry is populated by a diverse array of companies, ranging from global tech giants
                    to smaller niche players. Some of the key players in the industry include:</p>
                <ul>
                    <li><span class="highlight">Inc.</span>: Known for its iconic products like the iPhone, iPad, Mac, and Apple Watch, Apple is a dominant force in the computer industry, offering a range of hardware, software, and services.</li>
                    <li><span class="highlight">Microsoft Corporation</span>: Microsoft is a leader in software development, with its Windows operating system being one of the most widely used in the world. The company also provides cloud services, productivity software, and gaming consoles.</li>
                    <li><span class="highlight">IBM (International Business Machines) Corporation</span>: IBM is renowned for its expertise in enterprise solutions, including hardware, software, and services. It has a strong presence in areas such as artificial intelligence, blockchain, and quantum computing.</li>
                    <li><span class="highlight">Intel Corporation</span>: As a major player in the semiconductor industry, Intel designs and manufactures microprocessors and other hardware components that power many computers and devices worldwide.</li>
                    <li><span class="highlight">HP Inc.</span>: HP is a prominent manufacturer of personal computers, printers, and related accessories. The company also offers a range of software and services to support its hardware products.</li>
                    <li><span class="highlight">Dell Technologies Inc.</span>: Dell is well-known for its computer hardware products, including desktops, laptops, servers, and storage devices. The company also provides IT services and solutions.</li>
                </ul>
                <br>
                <p>These are just a few examples of the key players in the computer industry. The industry is highly
                    competitive, with companies constantly striving to innovate and gain market share. The market
                    landscape is dynamic and ever-evolving, driven by technological advancements, customer demands, and
                    emerging trends (computer industry trends).</p>
                <p>Understanding the key players in the computer industry is essential for analyzing its strengths,
                    weaknesses, opportunities, and threats, which will be explored in the subsequent sections of this
                    article.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l1B">SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of the Computer Industry
                </h3>
                <p>Analyzing the computer industry requires a comprehensive examination of its strengths, weaknesses,
                    opportunities, and threats. This SWOT analysis provides insights into the internal and external
                    factors that shape the industry's landscape.</p>
                <br>
                <h3>Strengths of the Computer Industry</h3>
                <p>The computer industry boasts several strengths that contribute to its prominence and resilience.
                    These strengths include:</p>
                <ol>
                    <li><span class="highlight">Technological Advancements</span>: The industry has a track record of
                        significant technological advancements, ranging from the introduction of magnetic disk storage
                        by IBM in 1957 to the development of microprocessors by Intel in the 1970s, which revolutionized
                        the industry (Econlib).</li>
                    <li><span class="highlight">Global Influence</span>: The computer industry has a strong presence
                        worldwide, with leading companies such as Apple, ASML Holding, and Taiwan Semiconductor
                        Manufacturing (TSMC) making a substantial impact in regions like America, Europe, and Asia.</li>
                    <li><span class="highlight">Innovation and Adaptability</span>: The industry continues to thrive
                        through continuous innovation and adaptability. Technologies like artificial intelligence (AI),
                        cloud computing, and the Internet of Things (IoT) are driving new possibilities and expanding
                        market opportunities.</li>
                </ol>
                <br>
                <h3>Weaknesses of the Computer Industry</h3>
                <p>Despite its strengths, the computer industry faces certain weaknesses that warrant consideration:</p>
                <ol>
                    <li><span class="highlight">Cybersecurity Risks</span>: The increasing reliance on digital systems
                        exposes the industry to cybersecurity threats. Data breaches, privacy concerns, and the need for
                        robust cybersecurity measures pose ongoing challenges (IEEE Computer Society).</li>
                    <li><span class="highlight">Regulatory Scrutiny</span>: As the industry continues to play a crucial
                        role in shaping economies and societies globally, it faces increased regulatory scrutiny related
                        to data privacy, antitrust concerns, and ethical considerations (Nasdaq).</li>
                </ol>
                <br>
                <h3>Opportunities in the Computer Industry</h3>
                <p>The computer industry presents several opportunities for growth and expansion:</p>
                <ol>
                    <li><span class="highlight">Emerging Technologies</span>: The industry is at the forefront of
                        emerging technologies such as AI, 5G, augmented reality, quantum computing, and blockchain.
                        These technologies have the potential to revolutionize various sectors and open up new avenues
                        for innovation and profitability (Cointelegraph).</li>
                    <li><span class="highlight">Increasing Demand for IT Professionals</span>: The rising demand for
                        skilled professionals in areas such as cybersecurity, data analytics, and software development
                        creates ample opportunities for job growth and career advancement within the industry.</li>
                </ol>
                <br>
                <h3>Threats on the Computer Industry</h3>
                <p>The computer industry also faces certain threats that could impact its growth and stability:</p>
                <ol>
                    <li><span class="highlight">Intense Competition</span>: The industry is highly competitive, with
                        major players vying for market dominance. Intense competition can lead to price wars, reduced
                        profit margins, and the need for continuous innovation to stay ahead.</li>
                    <li><span class="highlight">Economic Uncertainty</span>: Economic fluctuations and geopolitical
                        factors can significantly impact the computer industry's growth and investment opportunities.
                        Economic downturns may lead to reduced consumer spending and delayed technology adoption.</li>
                </ol>
                <br>
                <p>By conducting a comprehensive SWOT analysis, stakeholders in the computer industry can gain valuable
                    insights into the industry's current state and future prospects. This analysis aids in strategic
                    decision-making, allowing companies to leverage strengths, address weaknesses, seize opportunities,
                    and mitigate potential threats for sustainable growth and success.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l1C">Evolution of the Computer Industry</h3>
                <p>The computer industry has undergone significant evolution since its inception, marked by several
                    milestones and technological innovations. Understanding the historical development of the industry
                    provides valuable insights into its current state and future prospects.</p>
                <br>
                <h3>Milestones in the Computer Industry</h3>
                <p>The computer industry's journey began with groundbreaking milestones that paved the way for the
                    digital revolution we witness today. Here are some key milestones in the evolution of the computer
                    industry:</p>
                <ol>
                    <li>In <span class="highlight">1957</span>, IBM introduced the 305 RAMAC, the world's first computer
                        storage device to use magnetic disk storage, also known as a hard drive. This innovation
                        revolutionized data storage capabilities and laid the foundation for the computer industry as we
                        know it today.</li>
                    <li>The introduction of microprocessors in the early <span class="highlight">1970s</span>by Intel
                        marked another significant milestone. Microprocessors enabled the development of smaller, more
                        affordable computers, leading to the emergence of personal computers and a substantial increase
                        in computer adoption across various sectors.</li>
                    <li>In <span class="highlight">1981</span>, IBM released the IBM Personal Computer (PC), which
                        quickly became a standard in the industry. This move by IBM legitimized the personal computer
                        market and encouraged other manufacturers to develop their own personal computers, fueling
                        competition and innovation.</li>
                    <li>The emergence of the internet in the <span class="highlight">1990s</span>brought about a
                        paradigm shift in the computer industry. It facilitated global communication, e-commerce, and
                        the development of new business models. Tech giants like Microsoft, Apple, Google, and Amazon
                        thrived in the digital era, reshaping the landscape of the computer industry.</li>
                </ol>
                <br>
                <h3>Technological Innovations in the Computer Industry</h3>
                <p>Technological innovations have been instrumental in driving the evolution of the computer industry.
                    Here are some notable innovations that have significantly impacted the industry:</p>
                <ol>
                    <li><span class="highlight">Artificial Intelligence (AI)</span>: AI has emerged as a transformative
                        technology, enabling computers to perform tasks that typically require human intelligence. It
                        has applications in various fields, including healthcare, finance, and transportation.
                        AI-powered systems can analyze vast amounts of data, make predictions, and automate
                        decision-making processes, revolutionizing industries and driving further advancements in the
                        computer industry.</li>
                    <li><span class="highlight">Internet of Things (IoT)</span>: The IoT refers to the network of
                        interconnected devices that can communicate and exchange data. It has opened up new
                        possibilities for automation, efficiency, and connectivity. From smart homes to industrial
                        applications, the IoT has expanded the reach of the computer industry, creating opportunities
                        for innovation and growth.</li>
                    <li><span class="highlight">Quantum Computing</span>: Quantum computing is a field that holds
                        immense potential for solving complex problems beyond the capabilities of classical computers.
                        By harnessing the principles of quantum mechanics, quantum computers can perform calculations at
                        an exponential speed, opening new frontiers in areas such as drug discovery, financial modeling,
                        and climate change simulation. Although still in its early stages, quantum computing is expected
                        to revolutionize the computer industry in the coming years.</li>
                    <li><span class="highlight">Cloud Computing</span>: Cloud computing has transformed the way
                        businesses and individuals store, process, and access data. It provides on-demand access to
                        computing resources, enabling scalability, flexibility, and cost-efficiency. Cloud computing has
                        become an integral part of the computer industry, powering various applications and services,
                        ranging from storage and software development to artificial intelligence and machine learning.
                    </li>
                    <li><span class="highlight">Cybersecurity</span>: With the increasing reliance on digital systems
                        and connectivity, cybersecurity has become a critical aspect of the computer industry. The
                        industry has witnessed advancements in cybersecurity measures and technologies to protect
                        sensitive data, networks, and infrastructure from cyber threats. Ensuring robust cybersecurity
                        is essential to maintain trust and drive further innovation in the computer industry.</li>
                </ol>
                <br>
                <p>The evolution of the computer industry has been shaped by these milestones and technological
                    innovations. Looking ahead, emerging technologies and trends, such as AI, IoT, quantum computing,
                    cloud computing, and cybersecurity, will continue to drive advancements in the industry and shape
                    its future trajectory.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l1D">Emerging Trends in the Computer Industry</h3>
                <p>The computer industry is constantly evolving with the emergence of new technologies and trends.
                    Staying up to date with these developments is crucial for businesses to remain competitive. In this
                    section, we will explore some of the key emerging trends in the computer industry, including
                    Artificial Intelligence (AI), Internet of Things (IoT), Quantum Computing, Cloud Computing, and
                    Cybersecurity.</p>
                <br>
                <h3><span class="highlight">Artificial Intelligence (AI) in the Computer Industry</span></h3>
                <p>Artificial Intelligence (AI) remains at the forefront of emerging technologies in the computer
                    industry. Advancements in AI, such as Generative AI and explainable AI, are pushing the boundaries
                    of mimicking human output and are being evaluated for business applications and ethical
                    implications. Generative AI technologies, like ChatGPT, are revolutionizing natural language
                    processing and have the potential for various applications across industries.</p>
                <br>
                <h3><span class="highlight">Internet of Things (IoT) in the Computer Industry</span></h3>
                <p>The Internet of Things (IoT) is transforming the computer industry by enabling the interconnection of
                    various devices and systems. With the increasing bandwidth provided by 5G networks, IoT devices are
                    proliferating across industries. However, this growth also necessitates an increased focus on
                    enhancing cybersecurity measures to protect interconnected devices from cyberattacks. The
                    integration of IoT technologies is expected to revolutionize industries such as healthcare,
                    manufacturing, and transportation.</p>
                <br>
                <h3><span class="highlight">Quantum Computing in the Computer Industry</span></h3>
                <p>Quantum Computing is an emerging field that leverages the principles of quantum mechanics to perform
                    complex computations. While still in its early stages, quantum computing has the potential to
                    revolutionize computational power and solve problems that are currently intractable for classical
                    computers. As the technology progresses, it is expected to have a significant impact on various
                    sectors, including cryptography, optimization, and drug discovery.</p>
                <br>
                <h3><span class="highlight">Cloud Computing in the Computer Industry</span></h3>
                <p>Cloud Computing continues to be a major trend in the computer industry, offering flexible and
                    scalable computing resources over the internet. With the increasing demand for storage and
                    processing power, organizations are adopting cloud-based solutions to enhance their capabilities and
                    reduce infrastructure costs. Additionally, standalone 5G networks are leveraging cloud-based
                    architecture to enable advanced technologies like autonomous vehicles and precision robotics
                    (CompTIA).</p>
                <br>
                <h3><span class="highlight">Cybersecurity in the Computer Industry</span></h3>
                <p>As technology advances, cybersecurity becomes an increasingly critical concern. With the
                    proliferation of connected devices and the growing threat landscape, organizations are prioritizing
                    cybersecurity measures to protect their systems and data. Cybersecurity encompasses a range of
                    practices, including network security, data protection, and threat intelligence. Implementing robust
                    cybersecurity measures is essential to safeguard against cyberattacks and ensure the privacy and
                    integrity of sensitive information.</p>
                <br>
                <p>By keeping updated of these emerging trends in the computer industry, businesses can position
                    themselves for growth and adapt to the evolving technological landscape. Embracing these trends,
                    whether through the adoption of AI-powered solutions, leveraging IoT devices, exploring the
                    potential of quantum computing, harnessing the benefits of cloud computing, or implementing robust
                    cybersecurity practices, can provide organizations with a competitive edge in today's digital age.
                </p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l1E">Global Landscape of the Computer Industry</h3>
                <p>The computer industry encompasses a global market that is driven by leading companies, market
                    capitalization, and regional dynamics. Understanding the global landscape of the computer industry
                    is essential for comprehensive industry analysis. In this section, we will explore the leading
                    companies in the computer industry, market capitalization, and regional analysis.</p>
                <br>
                <h3><span class="highlight">Leading Companies in the Computer Industry</span></h3>
                <p>The computer industry is home to several prominent companies that shape the technological landscape.
                    In America, Apple stands as the largest tech company by market capitalization, with a staggering
                    market cap of over $2.4 trillion, showcasing its dominance in the industry. Other key players in the
                    American computer industry include Microsoft, Alphabet (the parent company of Google), Amazon.com,
                    and NVIDIA, which collectively contribute to the industry's growth and innovation.</p>
                <p><span class="highlight">Europe</span>also boasts significant players in the computer industry
                    market. ASML Holding, a Dutch semiconductor equipment manufacturer, holds a notable market cap of
                    over $332 billion, solidifying its position as a key player in the European market. These companies
                    contribute to the region's technological advancements and economic growth.</p>
                <p><span class="highlight">Asia</span>is another region where the computer industry thrives. Companies
                    like Taiwan Semiconductor Manufacturing (TSMC) play a vital role in the global computer industry,
                    with a market cap exceeding $550 billion. The strong presence of Asian companies highlights the
                    region's prominence in technological innovation and manufacturing.</p>
                <br>
                <p>It's important to note that the global computer industry analysis also includes regions categorized
                    as ‚ÄúOthers.‚Äù In this category, companies like Tencent Holdings operate, with a market cap surpassing
                    $560 billion. This diversity in the global tech market showcases the contributions and
                    competitiveness of various players (Companies Market Cap).</p>
                <br>
                <h3><span class="highlight">Market Capitalization in the Computer Industry</span></h3>
                <p>Market capitalization provides insight into the size and value of companies in the computer industry.
                    As of March 31, 2023, the top five IT hardware companies in the world by market capitalization are
                    Apple Inc, Microsoft Corp, Alphabet Inc, Amazon.com Inc, and NVIDIA Corp. These companies
                    collectively had a total market cap of $10,092,106 million.</p>
                <p>Among these top companies, Apple Inc holds the highest market capitalization, reaching $2,609,039
                    million. Microsoft Corp follows closely with a market cap of $2,146,049 million, while Alphabet Inc
                    holds a market cap of $1,330,082 million. The lowest market capitalization among the top five IT
                    hardware companies belongs to ASML Holding NV, with a market cap of $273,190 million.</p>
                <p>The combined market capitalization of the top 10 IT hardware companies in the world was $10,092,106
                    million as of March 31, 2023. This demonstrates the significant economic impact and influence of
                    these companies within the computer industry. The United States, in particular, emerges as a
                    dominant player in the technology and communications sector (GlobalData).</p>
                <br>
                <h3><span class="highlight">Regional Analysis of the Computer Industry</span></h3>
                <p>The computer industry's global landscape involves regional dynamics that contribute to its overall
                    growth and development. Different regions showcase unique strengths and characteristics within the
                    industry. While the American computer industry is home to major tech giants like Apple, Microsoft,
                    and Alphabet, Europe stands out with companies like ASML Holding that play a significant role in the
                    industry's advancement.</p>
                <p>Asia, on the other hand, boasts innovation and manufacturing prowess, with companies like TSMC
                    leading the way in semiconductor manufacturing. The ‚ÄúOthers‚Äù category encompasses companies such as
                    Tencent Holdings, highlighting the diverse and competitive nature of the global tech market.</p>
                <p>Regional analysis provides valuable insights into market trends, consumer behavior, and regulatory
                    environments, shaping the computer industry's future. Understanding these regional dynamics is
                    crucial for businesses and stakeholders operating in the computer industry, as it allows for
                    targeted strategies and market adaptation.</p>
                <p>As the computer industry continues to evolve, the global landscape will witness shifts and new
                    players emerging. Monitoring industry trends, computer industry growth, competition, and market
                    share will be essential for staying ahead in this dynamic and competitive sector.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l1F">Future Outlook for the Computer Industry</h3>
                <p>As technology continues to advance at a rapid pace, the future of the computer industry holds both
                    exciting opportunities and significant challenges. In this section, we will explore predictions for
                    the computer industry, discuss the challenges and opportunities it faces, and highlight the
                    regulatory and ethical considerations that shape its trajectory.</p>
                <br>
                <h3>Predictions for the Computer Industry</h3>
                <p>The ongoing development of technologies such as artificial intelligence (AI), cloud computing,
                    quantum computing, and the Internet of Things (IoT) continues to drive innovation and growth in the
                    computer industry, shaping its future (Econlib). Here are some key predictions for the computer
                    industry:</p>
                <ol>
                    <li><span class="highlight">Artificial Intelligence (AI)</span>: AI remains at the forefront of
                        emerging technologies, with advancements like generative AI and a heightened focus on
                        explainable AI and ethical considerations. The continued evolution of AI is expected to
                        revolutionize various sectors, including healthcare, finance, and manufacturing, by enhancing
                        efficiency, automation, and decision-making processes.</li>
                    <li><span class="highlight">Internet of Things (IoT)</span>: The proliferation of IoT devices,
                        driven by increasing bandwidth from 5G networks, is set to transform industries across the
                        board. However, to fully realize the potential of IoT, a significant focus will be placed on
                        enhancing cybersecurity measures to protect interconnected devices from cyberattacks.</li>
                    <li><span class="highlight">Quantum Computing</span>: The field of quantum computing is experiencing
                        rapid growth, with major investments from tech giants like IBM, Google, and Microsoft. By
                        leveraging the principles of quantum mechanics, quantum computers have the potential to solve
                        complex problems exponentially faster than traditional computers. By 2030, the quantum computing
                        market is projected to reach $65 billion (Computer Science.org).</li>
                    <li><span class="highlight">Cloud Computing</span>: The adoption of cloud-based data management and
                        storage solutions is expected to continue its upward trajectory. By 2024, over 50% of all
                        businesses are projected to rely on cloud-based solutions, moving away from on-premise storage.
                        This shift towards the cloud allows for scalability, flexibility, and cost-effectiveness in
                        managing data and applications (IEEE Computer Society).</li>
                </ol>
                <br>
                <h3>Challenges and Opportunities in the Computer Industry</h3>
                <p>While the computer industry presents numerous opportunities for growth and innovation, it also faces
                    several challenges. Understanding these challenges is crucial for organizations to navigate the
                    evolving landscape effectively. Some key challenges and opportunities in the computer industry
                    include:</p>
                <ol>
                    <li><span class="highlight">Cybersecurity</span>: The increasing reliance on technology and
                        interconnected systems brings forth the challenge of cybersecurity. The industry must address
                        the growing concerns around data breaches, privacy, and cyber threats. The demand for
                        cybersecurity professionals is on the rise, and organizations must invest in robust security
                        measures to protect sensitive data and infrastructure.</li>
                    <li><span class="highlight">Global Competition</span>: The computer industry is highly competitive,
                        with numerous players vying for market share and technological dominance. Companies must
                        continually innovate and adapt to stay ahead of the competition. Additionally, emerging markets
                        present opportunities for expansion and growth, but also require careful market analysis and
                        adaptation to local regulations and consumer preferences.</li>
                    <li><span class="highlight">Regulatory and Ethical Considerations</span>: As technology evolves,
                        regulatory frameworks and ethical considerations become increasingly important. Balancing
                        innovation with responsible use, data privacy, and ethical AI deployment are critical concerns.
                        Organizations must navigate regulatory landscapes and establish ethical guidelines to ensure
                        compliance and public trust.</li>
                </ol>
                <br>
                <h3>Regulatory and Ethical Considerations in the Computer Industry</h3>
                <p>With the rapid advancement of technology, the computer industry faces regulatory and ethical
                    considerations that shape its development. Some key aspects to consider include:</p>
                <ol>
                    <li><span class="highlight">Data Privacy and Protection</span>: As technology becomes more
                        intertwined with daily life, protecting personal data and privacy is of paramount importance.
                        Stricter regulations, such as the General Data Protection Regulation (GDPR), require
                        organizations to handle personal data responsibly and transparently.</li>
                    <li><span class="highlight">Ethical AI Deployment</span>: The deployment of AI technologies raises
                        ethical questions regarding bias, transparency, and accountability. As AI algorithms become
                        increasingly complex and autonomous, it is crucial to ensure that they are developed and
                        deployed in an ethical and responsible manner.</li>
                    <li><span class="highlight">Workforce Impact</span>: Technological advancements, such as automation
                        and AI, have the potential to impact the workforce. As certain tasks become automated,
                        organizations must consider the implications for jobs and reskilling opportunities to ensure a
                        smooth transition into the future of work.</li>
                </ol>
                <br>
                <p>By addressing these regulatory and ethical considerations, the computer industry can forge a path
                    towards responsible and sustainable growth while building trust among consumers, stakeholders, and
                    society as a whole.</p>
                <p>The future outlook for the computer industry is promising, driven by emerging technologies and the
                    ever-increasing demand for innovative solutions. However, it is essential for organizations to stay
                    informed, adapt to changing market dynamics, and prioritize ethical practices to thrive in this
                    evolving landscape.</p>
                <br>
            </section>
            <section class="lessons"><!--LESSON 2-->
                <h2 id="l2">üî¨Lesson 2: Computing and Other Sciences</h2>
                <a href="https://openstax.org/books/introduction-computer-science/pages/1-1-computer-science" class="source">
                    <h3 id="l1">Source: Openstax.org</h3>
                </a>
                <a href="https://bigpictureschool.com/" class="source">
                    <h3 id="l1">Source: Bigpictureschool.com</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l2A">Introduction to Computer Science</h3>
                <br>
                <h3>Learning Objectives</h3>
                <p>By the end of this section, you will be able to:</p>
                <ul>
                    <li>Discuss the history that led to the creation of computer science as a field</li>
                    <li>Define computer science</li>
                    <li>Assess what computer science can do, as well as what it should not do</li>
                </ul>
                <br>
                <p>The field of computer science (CS) is the study of computing, which includes all phenomena related to
                    computers, such as the Internet. With foundations in engineering and mathematics, computer science
                    focuses on studying algorithms. An algorithm is a sequence of precise instructions that enables
                    computing. This includes components computers use to process information. By studying and applying
                    algorithms, computer science creates applications and solutions that impact all areas of society.
                    For example, computer science developed the programs that enable online shopping, texting with
                    friends, streaming music, and other technological processes.</p>
                <p>While computers are common today, they weren't always this pervasive. For those whose lives have been
                    shaped by computer technology, it can sometimes seem like computer technology is ahistorical:
                    computing often focuses on rapid innovation and improvement, wasting no time looking back and
                    reflecting on the past. Yet the foundations of computer science defined over 50, and as much as 100,
                    years ago very much shape what is possible with computing today.</p>
                <br>
                <h3>The Early History of Computing</h3>
                <ul>
                    <li>The first computing devices were not at all like the computers we know today. They were physical
                        calculation devices such as the abacus, which first appeared in many societies across the world
                        thousands of years ago. They allowed people to tally, count, or add numbers (Figure 1.2). Today,
                        abaci are still used in some situations, such as helping small children learn basic arithmetic,
                        keeping score in games, and as a calculating tool for people with visual impairments. However,
                        abaci are not common today because of the invention of number systems such as the Arabic number
                        system (0, 1, 2, 3, . . .), which included zero and place values that cannot be computed with
                        abaci. The concept of an algorithm was also invented around this time. Algorithms use inputs and
                        a finite number of steps to carry out arithmetic operations like addition, subtraction,
                        multiplication, and division, and produce outputs used in computing. Today‚Äôs computers still
                        rely on the same foundations of numbers, calculations, and algorithms, except at the scale of
                        billions of numbers and billions of calculations per second.</li>
                    <li>To introduce a concrete example of an algorithm, let us consider binary search algorithm, which
                        is used to locate a number in a sorted array of integers efficiently. The algorithm operates by
                        repeatedly dividing the search interval in half to perform the search. If the number being
                        searched is less than the integer in the middle of the interval, the interval is narrowed to the
                        lower half. In the alternative, the interval is narrowed to the upper half. The algorithm
                        repeatedly checks until the number is found or the interval is empty.</li>
                    <li>Algorithms may sound complicated, but they can be quite simple. For example, recipes to prepare
                        food are algorithms with precise directions for ingredient amounts, the process to combine
                        these, and the temperatures and cooking methods needed to transform the combined ingredients
                        into a specific dish. The dish is the output produced by following the algorithm of a recipe.
                    </li>
                </ul>
                <div class="center-image">
                    <img src="https://openstax.org/apps/image-cdn/v1/f=webp/apps/archive/20251118.192121/resources/57b3b7ba6536f85c5c16098b4cdca4cc9a2b1357">
                    <p>Figure 1.2 An abacus is one of the first calculators. (credit: ‚ÄúTraditional Chinese abacus
                        illustrating the suspended bead use‚Äù by Jccsvq/Wikimedia Commons, CC0)</p>
                </div>
                <ul>
                    <li>The next major development in the evolution of computing occurred in 1614 when John Napier, a
                        Scottish mathematician, developed logarithms, which express exponents by denoting the power that
                        a number must be raised to obtain another value. Logarithms provided a shortcut for making
                        tedious calculations and became the foundation for multiple analog calculating machines invented
                        during the 1600s.</li>
                    <li>Scientists continued to explore different ways to speed up or automate calculations. In the
                        1820s, English mathematician Charles Babbage invented the Difference Engine with the goal of
                        preventing human errors in manual calculations. The Difference Engine provided a means to
                        automate the calculations of polynomial functions and astronomical calculations.</li>
                    <li>Babbage followed the Difference Engine with his invention of the Analytical Engine. With
                        assistance from Ada Lovelace, the Analytical Engine was program-controlled and included features
                        like an integrated memory and an arithmetic logic unit. Lovelace used punched cards to create
                        sequencing instructions that could be read by the Analytical Engine to automatically perform any
                        calculation included in the programming code. With her work on the Analytical Engine, Lovelace
                        became the world‚Äôs first computer programmer.</li>
                    <li>The next major development in computing occurred in the late 1800s when Herman Hollerith, an
                        employee of the U.S. Census Office, developed a machine that could punch cards and count them.
                        In 1890, Hollerith‚Äôs invention was used to tabulate and prepare statistics for the U.S. census.
                    </li>
                    <li>By the end of the 1800s and leading into the early 1900s, calculators, adding machines,
                        typewriters, and related machines became more commonplace, setting the stage for the invention
                        of the computer. In the 1940s, multiple computers became available, including IBM‚Äôs Harvard Mark
                        1. These were the forerunners to the advent of the digital computer in the 1950s, which changed
                        everything and evolved into the computers and related technology we have today.</li>
                    <li>Around this time, computer science emerged as an academic discipline rooted in the principles of
                        mathematics, situated primarily in elite institutions, and funded by demand from the military
                        for use in missile guidance systems, airplanes, and other military applications. As computers
                        could execute programs faster than humans, computer science replaced human-powered calculation
                        with computer-powered problem-solving methods. In this way, the earliest academic computer
                        scientists envisioned computer science as a discipline that was far more intellectual and
                        cognitive compared to the manual calculation work that preceded it.</li>
                    <li>Richard Bellman was a significant contributor to this effort. A mathematics professor at
                        Princeton and later at Stanford in the 1940s, Bellman later went to work for the Rand
                        Corporation, where he studied the theory of multistage decision processes. In 1953, Bellman
                        invented dynamic programming,1 which is a mathematical optimization methodology and a technique
                        for computer programming. With dynamic programming, complex problems are divided into more
                        manageable subproblems. Each subproblem is solved, and the results are stored, ultimately
                        resulting in a solution to the overall complex problem.2 With this approach, Bellman helped
                        revolutionize computer programming and enable computer science to become a robust field.</li>
                </ul>
                <br>
            </section>
            <section class="layout">
                <h3 id="l2B">Computing and Formal Science</h3>
                <p>Formal science encompasses disciplines that study abstract structures, logical systems, and
                    mathematical relationships rather than empirical phenomena. Unlike natural sciences that investigate
                    the physical world or social sciences that examine human behavior, formal sciences focus on formal
                    systems defined by axioms, rules, and logical operations. The primary formal sciences include
                    mathematics, logic, statistics, theoretical computer science, and systems theory.</p>
                <br>
                <h3>First Principles Foundation</h3>
                <p>Starting from first principles, formal science rests on several fundamental concepts. The foundation
                    begins with the notion of abstraction‚Äîthe process of isolating essential properties while removing
                    irrelevant details. From this abstraction emerges the concept of formal systems, which consist of a
                    set of symbols, rules for manipulating these symbols, and axioms that serve as starting points for
                    logical reasoning.</p>
                <p>The core principle underlying all formal science is the idea that truth can be established through
                    logical deduction from accepted premises. This differs fundamentally from empirical sciences, where
                    truth is established through observation and experimentation. In formal science, once axioms are
                    accepted and rules are established, conclusions follow necessarily through logical reasoning.</p>
                <br>
                <h3>Essential Characteristics</h3>
                <p>Formal sciences possess several defining characteristics that distinguish them from other branches of
                    knowledge. They operate with precise definitions and unambiguous terms, ensuring that concepts have
                    exact meanings within their contexts. They employ rigorous logical reasoning, where each step in an
                    argument follows necessarily from previous steps according to established rules. They maintain
                    consistency, meaning that contradictory statements cannot both be true within the same system.</p>
                <p>These disciplines also demonstrate completeness in their ideal form, where every true statement
                    within the system can be proven using the system's rules and axioms. They exhibit universality, as
                    their truths hold across all possible contexts that satisfy the system‚Äôs conditions, independent of
                    time, place, or specific circumstances.</p>
                <br>
                <h3>Relationship to Other Sciences</h3>
                <p>Formal sciences serve as the foundational language and toolset for other scientific disciplines.
                    Natural sciences rely on mathematics for measurement, modeling, and theoretical formulation. Social
                    sciences use statistics for data analysis and logical frameworks for theoretical development.
                    Applied sciences employ formal methods for engineering design and technological innovation.</p>
                <p>This relationship demonstrates that formal sciences provide the structural backbone that enables
                    other sciences to formulate precise theories, make quantitative predictions, and test hypotheses
                    rigorously. Without formal science, other disciplines would lack the precision and logical rigor
                    necessary for scientific advancement.</p>
                <br>
                <h3>Practical Applications and Significance</h3>
                <p>The importance of formal science extends beyond theoretical considerations into practical
                    applications that shape modern society. Computer science relies on formal logic and mathematical
                    structures to design algorithms and software systems. Engineering disciplines use mathematical
                    models to design safe and efficient structures. Economic theory employs mathematical frameworks to
                    understand market behavior and optimize resource allocation.</p>
                <p>Formal science thus represents humanity's systematic approach to understanding abstract relationships
                    and logical structures. By starting with basic principles of abstraction and logical reasoning,
                    formal sciences create the intellectual tools that enable precise thinking and problem-solving
                    across all domains of human knowledge and activity.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l2C">Computing and Natural Science</h3>
                <p>Natural science represents the systematic study of the natural world through observation,
                    experimentation, and the formulation of testable explanations. At its core, natural science seeks to
                    understand how the universe operates by identifying patterns, establishing cause-and-effect
                    relationships, and developing theories that can predict future phenomena.</p>
                <br>
                <h3>Foundational Principles</h3>
                <p>Natural science rests on several fundamental assumptions that form its conceptual foundation. The
                    first principle holds that the natural world operates according to consistent, discoverable laws.
                    This means that similar conditions will produce similar results, allowing scientists to identify
                    reliable patterns in nature. The second principle assumes that human senses and instruments can
                    provide accurate information about the world, though this information must be verified through
                    rigorous testing.</p>
                <p>The third foundational principle establishes that natural phenomena have natural explanations. Rather
                    than attributing events to supernatural causes, natural science seeks explanations within the
                    framework of physical, chemical, and biological processes. This principle drives scientists to look
                    for mechanisms that can account for observed phenomena through natural laws and processes.</p>
                <br>
                <h3>The Scientific Method as Core Framework</h3>
                <p>The scientific method provides the operational framework for natural science. This systematic
                    approach begins with careful observation of natural phenomena, followed by the formation of
                    hypotheses that offer potential explanations. Scientists then design controlled experiments to test
                    these hypotheses, collecting data that either supports or refutes their proposed explanations.</p>
                <p>This process incorporates crucial elements of reproducibility and peer review. Other scientists must
                    be able to replicate experiments and obtain similar results, ensuring that findings represent
                    genuine discoveries rather than isolated occurrences or experimental errors. The requirement for
                    peer review adds another layer of verification, as experts in relevant fields evaluate the
                    methodology, analysis, and conclusions before accepting new findings.</p>
                <br>
                <h3>Major Branches and Their Interconnections</h3>
                <p>Natural science encompasses several major disciplines, each focusing on different aspects of the
                    natural world while sharing common methodological approaches. Physics examines the fundamental
                    properties of matter and energy, establishing the basic laws that govern all natural phenomena.
                    Chemistry builds upon physical principles to understand how atoms and molecules interact, combine,
                    and transform.</p>
                <p>Biology applies both physical and chemical principles to understand living systems, from individual
                    cells to complex ecosystems. Earth sciences integrate concepts from physics, chemistry, and biology
                    to comprehend planetary processes and the history of our planet. Each discipline contributes unique
                    perspectives while drawing upon insights from the others, creating a comprehensive understanding of
                    natural phenomena.</p>
                <br>
                <h3>Evidence-Based Knowledge Building</h3>
                <p>Natural science advances through the systematic accumulation of evidence-based knowledge. Scientific
                    theories represent well-substantiated explanations supported by extensive experimental evidence and
                    capable of making accurate predictions. These theories undergo continuous refinement as new evidence
                    emerges, demonstrating the self-correcting nature of scientific inquiry.</p>
                <p>The process distinguishes between correlation and causation, recognizing that simultaneous occurrence
                    of events does not necessarily indicate a causal relationship. Scientists employ controlled
                    experiments and statistical analysis to establish genuine causal connections, building reliable
                    knowledge about how natural systems function.</p>
                <br>
                <h3>Quantitative Analysis and Mathematical Modeling</h3>
                <p>Mathematics serves as the language of natural science, providing tools for precise measurement,
                    statistical analysis, and theoretical modeling. Quantitative approaches allow scientists to identify
                    subtle patterns, test theories with precision, and make accurate predictions about future phenomena.
                </p>
                <p>Mathematical models help scientists understand complex systems by representing key relationships and
                    variables in simplified forms. These models can reveal underlying principles that might not be
                    apparent through observation alone, enabling deeper insights into natural processes.</p>
                <br>
                <h3>Predictive Power and Practical Applications</h3>
                <p>The ultimate test of scientific understanding lies in its predictive power and practical
                    applications. Successful scientific theories not only explain existing observations but also
                    accurately predict the outcomes of new experiments and the behavior of natural systems under
                    different conditions.</p>
                <p>This predictive capability enables the development of technologies that harness natural phenomena for
                    human benefit, from medical treatments based on biological understanding to engineering applications
                    grounded in physical principles. The practical success of these applications provides strong
                    validation for the underlying scientific theories.</p>
                <p>Natural science thus represents humanity's most reliable method for understanding the natural world,
                    built upon systematic observation, rigorous experimentation, and continuous refinement of knowledge
                    through evidence-based inquiry. Its strength lies in its commitment to testing ideas against reality
                    and its willingness to revise understanding when new evidence demands it.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l2D">Computing and Social Science</h3>
                <p>Social science represents the systematic study of human behavior, relationships, and societies using
                    empirical methods and theoretical frameworks. To understand this field through first principles, we
                    must begin with its fundamental components and build upward.</p>
                <br>
                <h3>The Foundation: What Constitutes Social Science</h3>
                <p>Social science emerges from a basic premise: human behavior follows patterns that can be observed,
                    measured, and analyzed. Unlike natural sciences that study physical phenomena, social science
                    examines the complex interactions between individuals, groups, and institutions. The field
                    encompasses disciplines such as sociology, psychology, economics, political science, anthropology,
                    and geography.</p>
                <br>
                <h3>Core Assumptions and Principles</h3>
                <p>Several fundamental assumptions underpin social science methodology. First, human behavior, while
                    complex, exhibits regularities that can be studied systematically. Second, social phenomena can be
                    understood through careful observation and analysis, even when controlled experimentation proves
                    difficult or impossible. Third, social reality exists both objectively through observable actions
                    and subjectively through individual experiences and interpretations.</p>
                <p>The scientific method in social science adapts to accommodate human complexity. Researchers employ
                    various approaches including quantitative analysis, qualitative investigation, and mixed methods to
                    capture different dimensions of social reality. This methodological diversity reflects the
                    recognition that human behavior operates across multiple levels simultaneously.</p>
                <br>
                <h3>The Challenge of Studying Human Systems</h3>
                <p>Social science confronts unique challenges that distinguish it from natural sciences. Human beings
                    possess consciousness, intentionality, and the capacity for reflexivity, meaning they can change
                    their behavior based on their understanding of research findings. This creates a dynamic
                    relationship between knowledge and its subject matter that does not exist in physics or chemistry.
                </p>
                <p>Additionally, social phenomena involve emergent properties that arise from collective behavior but
                    cannot be reduced to individual actions alone. Markets, cultures, and political systems exhibit
                    characteristics that transcend the sum of their individual components, requiring analytical
                    frameworks that can accommodate both micro and macro levels of analysis.</p>
                <br>
                <h3>Evidence and Validation</h3>
                <p>Social science establishes validity through multiple forms of evidence. Quantitative approaches rely
                    on statistical analysis, surveys, and experimental designs to identify patterns and relationships.
                    Qualitative methods use interviews, ethnography, and case studies to understand meaning and context.
                    The convergence of findings across different methodologies strengthens confidence in social
                    scientific conclusions.</p>
                <p>Replication and peer review serve as quality control mechanisms, though the context-dependent nature
                    of many social phenomena makes exact replication challenging. Instead, social science often relies
                    on conceptual replication, where similar patterns emerge across different settings and populations.
                </p>
                <br>
                <h3>Practical Applications and Limitations</h3>
                <p>Social science generates knowledge that informs policy decisions, organizational management, and
                    individual choices. Economic models guide fiscal policy, psychological research influences
                    educational practices, and sociological insights shape urban planning. However, the predictive power
                    of social science remains limited compared to natural sciences due to the inherent complexity and
                    variability of human systems.</p>
                <p>The field acknowledges these limitations while continuing to refine its methods and theoretical
                    frameworks. Social science provides probabilistic rather than deterministic explanations, offering
                    insights into likely outcomes rather than certain predictions.</p>
                <p>Through this first principles analysis, social science emerges as a rigorous yet adaptive field that
                    applies scientific thinking to understand human societies while recognizing the unique challenges
                    posed by conscious, reflexive subjects operating within complex, evolving systems.</p>
                <br>
            </section>
            <section class="lessons"><!--LESSON 3-->
                <h2 id="l3">üî¨Lesson 3: The Computing System</h2>
                <a href="https://www.techtarget.com/searchwindowsserver/definition/system" class="source">
                    <h3 id="l1">Source: Techtarget.com</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l3A">Introduction to Computer System</h3>
                <ul>
                    <li>A computer system consists of hardware components that have been carefully chosen so that they
                        work well together and software components or programs that run in the computer.</li>
                    <li>The main software component is itself an operating system (OS) that manages and provides
                        services to other programs that can be run in the computer.</li>
                    <li>In its most basic form, a computer system is a programmable electronic device that can accept
                        input; store data; and retrieve, process and output information.</li>
                </ul>
                <br>
                <h3>Evolution of computer systems</h3>
                <p>Computers are programmable electronic devices that can process data. To comprehend what a computer
                    system is, it's important to analyze the history and evolution of computer system development over
                    the years.</p>
                <br>
                <h3>Early models</h3>
                <p>The history of computer systems goes way back to Charles Babbage's differential machines. Despite
                    never being completed, this machine is considered the first example of a computing system. It came
                    before the early 20th-century mainframes and large computers. The Von Neumann machine and others of
                    its kind were later used as the first massive, monolithic computers in the human world.</p>
                <br>
                <h3>The personal computer</h3>
                <p>The microprocessor revolution of the 1970s and 1980s saw the introduction of personal computers, also
                    known as desktop computers. The first true home computer that came with a monitor display was
                    released to the public in 1977. At the time, many large organizations used expensive and massive
                    computers. The personal computer employed a computer box as its main piece of hardware, together
                    with peripheral devices such as a mouse and keyboard and computer software that was downloaded into
                    floppy disks.</p>
                <br>
                <h3>Operating system</h3>
                <p>The operating system was initially created to support a complete computer system in a box and to
                    provide users with a common interface for using the software that operated on that hardware.
                    Additionally, the actual software components to execute on a specific operating system, such as
                    files, apps and executables, were also introduced. The first IBM PC, officially known as the IBM
                    Model 5150, ran Microsoft's MS-DOS operating system and had an Intel 8088 processor running at 4.77
                    MHz.</p>
                <br>
                <h3>Laptops</h3>
                <p>The laptops emerged as hardware became smaller and more portable over time. The Portal, the first
                    authorized portable microcomputer, debuted in 1980. It was built using an 8-bit, 2 MHz Intel 8085
                    processor and was equipped with a 64K byte random access memory (RAM).</p>
                <br>
                <h3>The Cloud</h3>
                <p>The introduction of the modern cloud in the early 2000s revolutionized software distribution and data
                    storage. The out-of-the-box software strategy was rendered obsolete in the enterprise IT sector as
                    software was provided digitally through the internet in place of physical media, such as floppy
                    disks and compact disks.</p>
                <br>
                <h3>Virtualization</h3>
                <p>The concept of hardware and software configurations has recently undergone a radical change thanks to
                    virtualization. Instead of using physical hardware, the majority of current computing systems use
                    virtualized computer systems. Through the use of virtualization, a single computer's hardware
                    resources can be split up into several virtual machines.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l3B">Components of a computer system</h3>
                <p>The components of a computer system are typically divided into hardware and software parts, which are
                    both essential in making a computer system functional.</p>
                <br>
                <h3>Hardware components</h3>
                <p>The hardware components include the computer itself; the physical parts inside the computer, such as
                    a circuit board and storage devices; and any peripherals attached to the computer. These components
                    can be either classified as input devices, such as a mouse or keyboard, or output devices, such as a
                    monitor or a printer. While output devices reflect or display user data, input devices are designed
                    to accept user data.</p>
                <div class="center-image">
                    <img src="https://www.techtarget.com/rms/onlineimages/conceptual_overview_of_a_computer_system-f.png">
                    <p>Screenshot showing the CPU and storage unit of a computer system</p>
                </div>
                <p>The following are common hardware components of a computer system:</p>
                <ul>
                    <li>Keyboard.</li>
                    <li>Monitor.</li>
                    <li>Mouse.</li>
                    <li>Printer.</li>
                    <li>Computer case.</li>
                    <li>Graphics card.</li>
                    <li>Motherboard.</li>
                    <li>Power supply unit.</li>
                    <li>Central processing unit (CPU).</li>
                    <li>RAM.</li>
                    <li>Hard disk drive.</li>
                    <li>Solid state drive.</li>
                    <li>DVD-ROM.</li>
                </ul>
                <br>
                <h3>Software components</h3>
                <p>Software components are the set of instructions that are stored and run on the computer hardware. The
                    software controls how a computer system works. It can be grouped into the following two categories:
                </p>
                <ul>
                    <li>System software. Programs that are needed for the computer to function, including the OS,
                        utilities software, programming language translators and library routines.</li>
                    <li>Application Software. Programs that let a user perform particular tasks, including word
                        processing, database management, spreadsheet calculations, web browsing, gaming, programming and
                        graphic design. Additionally, it may also include specific programs such as accounts, payroll
                        and air traffic control.</li>
                </ul>
                <br>
            </section>
            <section class="layout">
                <h3 id="l3C">Types of computer systems</h3>
                <p>Depending on the applications and performance requirements, numerous computer system types are
                    utilized in various fields. Computers are typically divided into two groups based on their size and
                    their capacity for handling data.</p>
                <p>The following are computer system types based on their size:</p>
                <ol>
                    <li>Microcomputers. These are commonly used for personal computing purposes. They carry a single
                        processor for their CPU and a microprocessor that controls it. Examples of microcomputers
                        include laptops, tablets, mobile phones and personal digital assistants.</li>
                    <li>Minicomputers. These computers were created in the middle of the 1960s and the early
                        minicomputers replaced vacuum tubes with transistors. They have a larger storage capacity and
                        faster computing power than microcomputers and are capable of supporting hundreds of users
                        simultaneously. Devices such as the Apple iPad, iPod and Samsung Tab are examples of
                        minicomputers.</li>
                    <li>Medium-sized computers. Compared to both microcomputers and minicomputers, these computer
                        systems offer faster speeds and a larger storage space. These computers have numerous disk
                        drives that can be utilized to process online access requests as well as a sizable number of
                        high-speed input-output devices. Common example of a medium-sized computer includes IBM's Power
                        Systems.</li>
                    <li>Mainframe computers. Large, multi-user mainframe computers can access billions of pieces of data
                        and are capable of processing millions of instructions each second. With little operator input,
                        mainframes can support multiple computer programs and hundreds of thousands of users at the same
                        time. The banking and telecom sectors are a good candidate for mainframe computers as they
                        process data in large quantities.</li>
                    <li>Supercomputers. These computers are enormous in size and extremely powerful. They're
                        specifically designed to handle huge amounts of data. They're capable of executing hundreds of
                        millions of instructions every second. Supercomputers are typically used for
                        calculation-intensive tasks such as molecular modeling, climate research, weather forecasting,
                        quantum physics and physical stimulations.</li>
                </ol>
                <br>
                <p>The following are computer system types based on their data handling capacity:</p>
                <ol>
                    <li>Analog computer. This type of computer system continuously processes varying data. Without
                        translating it first into numbers and codes, it can simply accept the data from the equipment of
                        measurement. It gauges the constant variations in physical quantities, and a reading on a dial
                        or scale serves as the output. A speedometer or a mercury thermometer are examples of analog
                        computers.</li>
                    <li>Digital computer. Digital computers effortlessly calculate algorithms and logical processes at
                        rapid speeds. They use stored programs in their memory to process raw data as an input and then
                        output the result. Since they can only understand binary inputs, these computers convert the raw
                        input data to 0 and 1, after which the data is processed to create the result. Digital computers
                        include all current models of desktops, laptops, and cellphones.</li>
                    <li>Hybrid computer. This computer is a combination of both analog and digital computers. Hybrid
                        computers combine the speed of an analog computer with the accuracy and memory of a digital
                        computer. As a result, they can handle both continuous and discrete data. Hybrid computers
                        convert analog signals into digital signals for use when processing input data after accepting
                        analog signals as input. </li>
                </ol>
            </section>
            <section class="lessons"><!--LESSON 4-->
                <h2 id="l4">üî¢Lesson 4: Number System and Binary Arithmetic</h2>
                <a href="https://www.geeksforgeeks.org/maths/number-system-in-maths/" class="source">
                    <h3 id="l1">Source: Geeksforgeeks.org</h3>
                </a>
                <a href="https://www.tutorialspoint.com/digital-electronics/digital-electronics-binary-arithmetic.htm" class="source">
                    <h3 id="l1">Source: Tutorialspoint.com</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l4A">Introduction to Number System</h3>
                <p>Number System is a method of representing numbers with the help of a set of symbols and rules; it is
                    a mathematical notation used to represent quantities or values in various forms.</p>
                <p><em>Please remember every piece of data in a computer‚Äîwhether it's text, images, sound, video, code,
                        or memory addresses‚Äîis ultimately stored as binary, a string of 0s and 1s making numbers and
                        number systems the core of computing.</em></p>
                <ul>
                    <li>Humans understand decimal, and computers understand binary, so we have two different number
                        systems.</li>
                    <li>Binary can be long for large amount of data, so there are more systems like octal and
                        hexadecimal that allow binary sequence to be broken into groups making it less error-prone and
                        readable compared to binary.</li>
                </ul>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20250711155753434012/binary-code.webp">
                    <p>Fig: 1 Everything is stored in the computer in the form of binary.</p>
                </div>
                <p>As shown in Figure 1, binary is the foundation of all data representation in computers. Let's now
                    explore the different number systems that enable this process.</p>
                <p>Number systems provide a structured way to represent numbers, enabling arithmetic operations and
                    ensuring consistent, understandable notation.</p>
                <ul>
                    <li>A number system uses a base (or radix) to represent values.</li>
                    <li>The base refers to the number of unique digits, including zero, that a system uses to represent
                        numbers.</li>
                    <li>Each system has its own set of rules for representing.</li>
                </ul>
                <br>
            </section>
            <section class="layout">
                <h3 id="l4B">Types of Number Systems</h3>
                <p>Number systems are of various types based on their base value and the number of allowed digits.</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20251217155813658412/number_system.webp">
                </div>
                <br>
                <h4>Decimal Number System</h4>
                <p>The Decimal Number System is the standard system for denoting numbers.</p>
                <ul>
                    <li>It is also called the <b>base-10</b>system.</li>
                    <li>Digits used in it are <b>0, 1, 2, 3, 4, 5, 6, 7, 8, 9.</b></li>
                    <li>Each digit in the number is at a specific place value that is powers of 10.</li>
                    <li>From right to left - units has the place value as 10^0, Tens has the place value as 10^1,
                        Hundreds as 10^2, Thousands as 10^3, and so on.</li>
                </ul>
                <div class="center-image">
                    <img src="images/decimal-exp.png">
                </div>
                <br>
                <h4>Binary Number System</h4>
                <p>Binary Number System is the number system with <b>base 2.</b></p>
                <ul>
                    <li>The numbers are formed using two digits - <b>0 and 1.</b></li>
                    <li>Binary number system is very useful in electronic devices and computer systems because it can be
                        easily performed using just two state i.e. 0 and 1.</li>
                    <li>Each digit in the number is at a specific place value that is powers of 2.</li>
                    <li>From right to left - as powers of 2 (i.e. 2^0, 2^1, 2^2, etc).</li>
                </ul>
                <p>Binary Numbers can be converted to Decimal value by multiplying each digit with the place value and
                    then adding the result.</p>
                <div class="center-image">
                    <img src="images/binary-exp.png">
                </div>
                <br>
                <h4>Octal Number System</h4>
                <p>Octal Number System is the number system with <b>base 8.</b></p>
                <ul>
                    <li>The numbers are formed using 8 digits i.e. <b>0, 1, 2, 3, 4, 5, 6, 7.</b></li>
                    <li>Octal number system is useful for representing file permissions in Unix/Linux operating systems.
                    </li>
                    <li>Each digit in the number is at a specific place value that is powers of 8.</li>
                    <li>From right to left - as powers of 8 i.e. 8^0, 8^1, 8^2, etc.</li>
                </ul>
                <p>Octal Numbers can be converted to Decimal value by multiplying each digit with the place value and
                    then adding the result.</p>
                <div class="center-image">
                    <img src="images/octal-exp.png">
                </div>
                <br>
                <h4>Hexadecimal Number System is the number system with base 16.</h4>
                <p>Hexadecimal Number System is the number system with base 16.</p>
                <ul>
                    <li>The numbers are formed using 16 digits i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E and F.
                    </li>
                    <li>Hexadecimal Numbers are useful for handling memory address locations. </li>
                    <li>The digits from 0 to 9 are used as in the decimal system, but the numbers 10 to 15 are
                        represented using the letters A to F as follows: 10 is represented as A, 11 as B, 12 as C, 13 as
                        D, 14 as E, 15 as F.<br>ii. Place Value: the position of the digit. Each digit in the number is
                        at a specific place value that is powers of 16. (from right to left - as powers of 16 i.e. 16^0,
                        16^1, 16^2, etc)</li>
                </ul>
                <p>Hexadecimal Number System an be converted to Decimal value by multiplying each digit with the place
                    value and then adding the result.</p>
                <div class="center-image">
                    <img src="images/hexd-exp.png">
                </div>
                <br>
            </section>
            <section class="layout">
                <h3 id="l4C">Conversion from Decimal to Other Number Systems</h3>
                <p>To convert decimal to another base, divide by the target base, record remainders from right to left
                    until the quotient is 0, then specify the base for each section (binary: base-2, octal: base-8,
                    hexadecimal: base-16 with A‚ÄìF for 10‚Äì15).</p>
                <br>
                <h4>Decimal to Binary Conversion </h4>
                <p>To see how a decimal number is converted to binary, consider the following example:</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20251217160411868183/Binary-Number---3.webp">
                </div>
                <p>Binary numbers use base-2. To convert a decimal number to binary, follow the steps given below:</p>
                <ul>
                    <li>Step 1: Divide the Decimal Number with the base of the number system to be converted to. Here
                        the conversion is to binary, hence the divisor will be 2.</li>
                    <li>Step 2: The remainder obtained from the division will become the least significant digit of the
                        new number.</li>
                    <li>Step 3: The quotient obtained from the division will become the next dividend and will be
                        divided by the base i.e. 2.</li>
                    <li>Step 4: The remainder obtained will become the second least significant digit i.e. it will be
                        added to the left of the previously obtained digit.</li>
                </ul>
                <p>Now, the steps 3 and 4 are repeated until the quotient obtained becomes 0, and the remainders
                    obtained after each iteration are added to the left of the existing digits.</p>
                <p>After all the iterations are over, the last obtained remainder will be termed as the Most Significant
                    digit.</p>
                <br>
                <h3>Decimal to Octal Conversion</h3>
                <p>Let's look at an example of converting a decimal number to octal:</p>
                <br>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20251217160411964274/Binary-Number---4.webp">
                </div>
                <p>Octal numbers use base-8. Here's the process:</p>
                <ul>
                    <li>Step 1: Divide the Decimal Number with the base of the number system to be converted to. Here
                        the conversion is to octal, hence the divisor will be 8.</li>
                    <li>Step 2: The remainder obtained from the division will become the least significant digit of the
                        new number.</li>
                    <li>Step 3: The quotient obtained from the division will become the next dividend and will be
                        divided by base i.e. 8.</li>
                    <li>Step 4: The remainder obtained will become the second least significant digit i.e. it will be
                        added to the left of the previously obtained digit.</li>
                </ul>
                <p>Now, the steps 3 and 4 are repeated until the quotient obtained becomes 0, and the remainders
                    obtained after each iteration are added to the left of the existing digits.</p>
                <br>
                <h3>Decimal to Hexadecimal Conversion</h3>
                <p>Here's an example of converting a decimal number to hexadecimal:</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20251217160412135323/Binary-Number---5.webp">
                </div>
                <p>Hexadecimal uses base-16, with digits 0‚Äì9 and A‚ÄìF (where A = 10, B = 11, C = 12, D = 13, E = 14, F =
                    15). Follow
                    these steps:</p>
                <ul>
                    <li>Step 1: Divide the Decimal Number with the base of the number system to be converted to. Here
                        the conversion is
                        to Hex hence the divisor will be 16. </li>
                    <li>Step 2: The remainder obtained from the division will become the least significant digit of the
                        new number.</li>
                    <li>Step 3: The quotient obtained from the division will become the next dividend and will be
                        divided by base i.e.
                        16.</li>
                    <li>Step 4: The remainder obtained will become the second least significant digit i.e. it will be
                        added to the left
                        of the previously obtained digit.</li>
                </ul>
                <p>Now, the steps 3 and 4 are repeated until the quotient obtained becomes 0, and the remainders
                    obtained after each
                    iteration are added to the left of the existing digits.</p>
                <p><em>NOTE: If the remainder is 10‚Äì15, use A‚ÄìF (e.g., A = 10, B = 11, C = 12, D = 13, E = 14, F =
                        15).</em></p>
            </section>
            <section class="layout">
                <h3 id="l4D">Conversion from Other Number Systems to Decimal</h3>
                <h4>Binary to Decimal Number System Conversion</h4>
                <p>For Integer Part:</p>
                <ul>
                    <li>Write down the binary number.</li>
                    <li>Multiply each digit by 2 raised to the power of its position, starting from 0 (rightmost digit).
                    </li>
                    <li>Add up the results of these multiplications.</li>
                    <li>The sum is the decimal equivalent of the binary integer.</li>
                </ul>
                <p>For Fractional Part:</p>
                <ul>
                    <li>Write down the binary fraction.</li>
                    <li>Multiply each digit by 2 raised to the negative power of its position, starting from -1 (first
                        digit after the
                        decimal point).</li>
                    <li>Add up the results of these multiplications.</li>
                    <li>The sum is the decimal equivalent of the binary fraction.</li>
                </ul>
                <div class="center-image">
                    <img src="images/binToDeci.png">
                </div>
                <br>
                <h4>Octal to Decimal Number System Conversion</h4>
                <p>For Integer Part:</p>
                <ul>
                    <li>Write down the octal number.</li>
                    <li>Multiply each digit by 8 raised to the power of its position, starting from 0 (rightmost digit).
                    </li>
                    <li>Add up the results of these multiplications.</li>
                    <li>The sum is the decimal equivalent of the octal integer.</li>
                </ul>
                <p>For Fractional Part:</p>
                <ul>
                    <li>Write down the octal fraction.</li>
                    <li>Multiply each digit by 8 raised to the negative power of its position, starting from -1 (first
                        digit after the
                        decimal point).</li>
                    <li>Add up the results of these multiplications.</li>
                    <li>The sum is the decimal equivalent of the octal fraction.</li>
                </ul>
                <div class="center-image">
                    <img src="images/octalToDeci.png">
                </div>
                <br>
                <h4>Hexadecimal to Decimal Conversion</h4>
                <p>For Integer Part:</p>
                <ul>
                    <li>Write down the hexadecimal number.</li>
                    <li>Multiply each digit by 16 raised to the power of its position, starting from 0 (rightmost
                        digit).</li>
                    <li>Add up the results of these multiplications.</li>
                    <li>The sum is the decimal equivalent of the hexadecimal integer.</li>
                </ul>
                <p>For Fractional Part:</p>
                <ul>
                    <li>Write down the hexadecimal fraction.</li>
                    <li>Multiply each digit by 16 raised to the negative power of its position, starting from -1 (first
                        digit after the
                        decimal point).</li>
                    <li>Add up the results of these multiplications.</li>
                    <li>The sum is the decimal equivalent of the hexadecimal fraction.</li>
                </ul>
                <div class="center-image">
                    <img src="images/hexaToDeci.png">
                </div>
                <br>
                <p><em>Important Note: For converting other number systems like hexadecimal to binary, binary to octal,
                        etc. It will be a two way process. The number is converted into decimal number first before
                        converting them into the corresponding
                        number system.</em></p>
                <p>Here is an example of octal to binary:</p>
                <div class="center-image">
                    <img src="images/numToNum.png">
                </div>
                <br>
            </section>
            <section class="layout">
                <h3 id="l4E">Arithmetic Operations of Binary Numbers</h3>
                <p>Binary is a base-2 number system that uses two states 0 and 1 to represent a number. We can also call
                    it to be a true
                    state and a false state. A binary number is built the same way as we build a normal decimal number.
                </p>
                <p>Binary arithmetic is an essential part of various digital systems. You can add, subtract, multiply,
                    and divide binary
                    numbers using various methods. These operations are much easier than decimal number arithmetic
                    operations because
                    the binary system has only two digits: 0 and 1. </p>
                <p>Binary additions and subtractions are performed as same in decimal additions and subtractions. When
                    we perform binary
                    additions, there will be two outputs: Sum (S) and Carry (C).</p>
                <ol>
                    <li>There are four rules for <b>binary addition</b>:
                        <div class="center-image">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20200414193953/223-1.png">
                        </div>
                    </li>
                    <br>
                    <li>There are four rules for <b>binary subtraction</b>:
                        <div class="center-image">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20230111081757/3164-1.png">
                        </div>
                    </li>
                    <br>
                    <li>There are four rules for <b>binary multiplication</b>:
                        <div class="center-image">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20200414194412/4108-1.png">
                            <p>Multiplication is always 0, whenever at least one input is 0.</p>
                        </div>
                    </li>
                    <br>
                    <li>There are four parts in any <b>division</b>: Dividend, Divisor, quotient, and remainder.
                        <div class="center-image">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20200414194524/580-1.png">
                            <p>The result is always not defined, whenever the divisor is 0</p>
                        </div>
                    </li>
                </ol>
                <br>
            </section>
            <section class="layout">
                <h3 id="l4F">Sample Problems of Binary Arithmetic.<h3></h3>
                    <h3>Binary Addition</h3>
                    <h4>Example 1</h4>
                    <p>Add two binary numbers, 1101 and 1110.</p>
                    <h4>Solution</h4>
                    <p>The binary addition of the given binary numbers is described below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-addition.jpg">
                    </div>
                    <h4>Explanation</h4>
                    <ul>
                        <li>Add 1 (rightmost bit of first number) and 0 (rightmost bit of the second number). It gives 1
                            + 0
                            = 1 (thus,
                            write down 1 as sum bit).</li>
                        <li>Add 0 (second rightmost bit of first number) and 1 (second rightmost bit of the second
                            number).
                            It gives 0 + 1 =
                            1 (write down 1 as sum bit).</li>
                        <li>Add 1 (third rightmost bit of first number) and 1 (third rightmost bit of second number). It
                            gives 1 + 1 = 10
                            (write down 0 as sum and 1 as carry).</li>
                        <li>Add 1 (leftmost bit of the first number), 1 (leftmost bit of second number) and 1 (carry).
                            It
                            gives 1 + 1 + 1 =
                            11 (write down 1 as sum and 1 as carry).</li>
                        <li>Write the end around carry 1 in the sum.</li>
                    </ul>
                    <p>Thus, the result is 11011.</p>
                    <br>
                    <h4>Example 2</h4>
                    <p>Add 1010 and 11011.</p>
                    <h4>Solution</h4>
                    <p>The binary addition of given numbers is explained below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-addition-numbers.jpg">
                    </div>
                    <h4>Explanation</h4>
                    <ul>
                        <li>Add 0 (rightmost bit of first number) and 1 (rightmost bit of second number). It gives 0 + 1
                            = 1
                            (write down 1
                            as sum).</li>
                        <li>Add 1 (second rightmost bit of first number) and 1 (second rightmost bit of second number).
                            It
                            gives 1 + 1 = 10
                            (write down 0 as sum and 1 as carry).</li>
                        <li>Add 0 (third rightmost bit of first number), 0 (third rightmost bit of second number), and 1
                            (carry). It gives 0
                            + 0 + 1 = 1 (write down 1 as sum).</li>
                        <li>Add 1 (leftmost bit of first number) and 1 (second leftmost bit of second number). It gives
                            1 +
                            1 = 10 (write
                            down 0 as sum and 1 as carry).</li>
                        <li>Add 1 (leftmost bit of second number) and 1 carry. It gives 1 + 1 = 10 (write down 0 as sum
                            and
                            1 as the end
                            around carry).</li>
                    </ul>
                    <p>Hence, the sum of 1010 and 11011 is 100101.</p>
                    <br>
                    <h3>Binary Subtraction</h3>
                    <h4>Example 1</h4>
                    <p>Subtract 1100 from 1101.</p>
                    <h4>Solution</h4>
                    <p>The subtraction of given binary numbers is given below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-subtraction.jpg">
                    </div>
                    <h4>Explanation</h4>
                    <ul>
                        <li>Subtract 0 (rightmost bit of second number) from 1 (rightmost bit of first number). It gives
                            1 0 = 1 (write down
                            1 as difference).</li>
                        <li>Subtract 0 (second rightmost bit of second number) from 0 (second rightmost bit of first
                            number). It gives 0 0 =
                            0 as result.</li>
                        <li>Subtract 1 (third rightmost bit of second number) from 1 (third rightmost bit of first
                            number). It gives 1 1 = 0
                            as result.</li>
                        <li>Subtract 1 (leftmost bit of second number) from 1 (leftmost bit of first number). It gives 1
                            1 = 0 as result.
                        </li>
                    </ul>
                    <p>Thus, the difference of 1101 and 1100 is 0001.</p>
                    <br>
                    <h4>Example 2</h4>
                    <p>Subtract 101 from 1111.</p>
                    <h4>Solution</h4>
                    <p>The subtraction of given binary numbers is explained below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-subtraction-numbers.jpg">
                    </div>
                    <h4>Explanation</h4>
                    <ul>
                        <li>Subtract rightmost bits: 1 1 = 0</li>
                        <li>Subtract second rightmost bits: 1 0 = 1</li>
                        <li>Subtract third rightmost bits: 1 1 = 0</li>
                        <li>Subtract leftmost bits: 1 0 = 1</li>
                    </ul>
                    <p>Thus, the result is 1010.</p>
                    <br>
                    <h3>Binary Multiplication</h3>
                    <h4>Example 1</h4>
                    <p>Multiply 1101 and 11.</p>
                    <h4>Solution</h4>
                    <p>The binary multiplication of given numbers is described below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-multiplication.jpg">
                    </div>
                    <h4>Explanation</h4>
                    <ul>
                        <li>Multiply the rightmost bit of the second number, 1 by each bit of the first number (1101).
                        </li>
                        <li>Now, shift the partial product one position to the left to perform the next multiplication.
                        </li>
                        <li>Multiply the leftmost bit of the second number, 1 by each bit of the first number (1101).
                        </li>
                        <li>Finally, sum up all the partial products to obtain the final product.</li>
                    </ul>
                    <p>Hence, the product of 1101 and 11 is 100111.</p>
                    <br>
                    <h4>Example 2</h4>
                    <p>Multiply 11011 and 110.</p>
                    <h4>Solution</h4>
                    <p>The multiplication of given binary numbers is demonstrated below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-multiplication-numbers.jpg">
                    </div>
                    <h4>Explanation</h4>
                    <ul>
                        <li>Multiply rightmost bit of the second number (0) by each bit of the first binary number
                            (11011).</li>
                        <li>Shift the partial product one position to the left.</li>
                        <li>Multiply the second rightmost bit of the second number (1) by each bit of the first binary
                            number (11011).</li>
                        <li>Again, shift the partial product one position to the left.</li>
                        <li>Multiply the leftmost bit of the second number (1) by each bit ofthe first number.</li>
                        <li>Then, sum up all the partial products to obtain the final product.</li>
                    </ul>
                    <p>Hence, the product of 11011 and 110 is 10100010.</p>
                    <br>
                    <h3>Binary Division</h3>
                    <h4>Example 1</h4>
                    <p>Divide 110011 by 11.</p>
                    <h4>Solution</h4>
                    <p>The division of the given binary numbers is explained below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-division.jpg">
                    </div>
                    <p>In this example of binary division, the quotient obtained is 10001 and the remainder is 0.</p>
                    <br>
                    <h4>Example 2</h4>
                    <p>Divide 11011 by 10.</p>
                    <h4>Solution</h4>
                    <p>The binary division of 11011 by 10 is explained below</p>
                    <div class="center-image">
                        <img src="https://www.tutorialspoint.com/digital-electronics/images/binary-division-numbers.jpg">
                    </div>
                    <p>In this example, the quotient is 1101 and the remainder is 1.</p>
                    <br>
                    <h3>Conclusion</h3>
                    <p>Binary arithmetic involves arithmetic operations performed on binary numbers. In general, the
                        four basic arithmetic
                        operations namely addition, subtraction, multiplication, and division are performed on binary
                        numbers.</p>
                    <br>
            </section>
            <section class="lessons"><!--LESSON 5-->
                <h2 id="l5">üîåLesson 5: Digital Logic System</h2>
                <a href="https://www.geeksforgeeks.org/digital-logic/boolean-algebra/" class="source">
                    <h3>Source: Geeksforgeeks.org</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l5A">Introduction to Boolean Algebra</h3>
                <p>Boolean Algebra is a branch of mathematics that deals with variables that have only two possible
                    values ‚Äî typically
                    denoted as 0 and 1 (or false and true). It focuses on binary variables and logic operations such as
                    AND, OR, and NOT.</p>
                <ul>
                    <li>Boolean Algebra provides a formal way to represent and manipulate logical statements and binary
                        operations.</li>
                    <li>It is the mathematical foundation of digital electronics, computer logic, and programming
                        conditions.</li>
                </ul>
                <br>
                <h4>Logical Operations</h4>
                <p>Various operations are used in Boolean algebra, but the basic operations that form the base of
                    Boolean Algebra are:</p>
                <ul>
                    <li>Negation or NOT Operation</li>
                    <li>Conjunction or AND Operation</li>
                    <li>Disjunction or OR Operation</li>
                </ul>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20240507171330/Boolean-Algebra-Operations.png">
                </div>
                <p>These operations have their symbols and precedence, and the table added below shows the ssymbolsand
                    the precedence of
                    these operators.</p>
                <div class="center-image">
                    <img src="images/logictable.png">
                </div>
                <p>We can easily define these operations using two Boolean variables.
                    <br>
                    Let's take two Boolean variables A and B that can have any of the two values 0 or 1, i.e., they can
                    be either OFF or ON.
                    Then these operations are explained as,
                </p>
                <br>
                <h4>Negation or NOT Operation</h4>
                <p>Using the NOT operation reverse the value of the Boolean variable from 0 to 1 or vice-versa. This can
                    be understood as:</p>
                <ul>
                    <li>If A = 1, then using NOT operation we have (A)' = 0</li>
                    <li>If A = 0, then using the NOT operation we have (A)' = 1</li>
                    <li>We also represent the negation operation as ~A, i.e if A = 1, ~A = 0</li>
                </ul>
                <br>
                <h4>Conjunction or AND Operation</h4>
                <p>Using the AND operation satisfies the condition if both the values of the individual variables are
                    true, and if any of
                    the values is false, then this operation gives a negative result. This can be understood as,</p>
                <ul>
                    <li>If A = True, B = True, then A . B = True</li>
                    <li>If A = True, B = False, Or A = false, B = True, then A . B = False</li>
                    <li>If A = False, B = False, then A . B = False</li>
                </ul>
                <br>
                <h4>Disjunction (OR) Operation</h4>
                <p>Using the OR operation satisfies the condition if any value of the individual variables is true; it
                    only gives a
                    negative result if both the values are false. This can be understood as,</p>
                <ul>
                    <li>If A = True, B = True, then A + B = True</li>
                    <li>If A = True, B = False, Or A = false, B = True, then A + B = True</li>
                    <li>If A = False, B = False, then A + B = False</li>
                </ul>
                <br>
            </section>
            <section class="layout">
                <h3 id="l5B">Boolean Algebra Table (Extended)</h3>
                <p>Given below is the Expression for the Boolean Algebra</p>
                <div class="center-image">
                    <img src="images/booltable.png">
                </div>
                <br>
                <h3>Boolean Expression and Variables</h3>
                <p>Boolean expression is an expression that produces a Boolean value when evaluated, i.e., it produces
                    either a true valueor a false value. Whereas Boolean variables are variables that store Boolean
                    numbers.
                    <br>
                    P + Q = R is a Boolean expression in which P, Q, and R are Boolean variables that can only store two
                    values: 0 and 1.
                    <br>
                    Thus, we can say that statements using Boolean variables and operating on Boolean operations are
                    Boolean Expressions.Some examples of Boolean expressions are,
                </p>
                <ul>
                    <li>A + B = True</li>
                    <li>A . B = True</li>
                    <li>(A)' = False</li>
                </ul>
                <br>
                <h3>Truth Tables</h3>
                <p>A truth table represents all the combinations of input values and outputs in a tabular manner. All
                    the possibilities of
                    the input and output are shown in it ,and hence the name truth table. In logic problems, truth
                    tables are commonly used
                    to represent various cases. T or 1 denotes 'True' & F or 0 denotes 'False' in the truth table.</p>
                <div class="center-image">
                    <img src="images/truthrow.png">
                </div>
                <p>Example: Draw the truth table of the conditions A + B and A . B ,where A and B are Boolean variables.
                    <br>
                    Solution:
                    <br>
                    The required Truth Table is,
                </p>
                <div class="center-image">
                    <img src="images/truth-exp.png">
                </div>
                <br>
            </section>
            <section class="layout">
                <h3 id="l5C">Laws for Boolean Algebra</h3>
                <p>Given below is the Expression for the Boolean Algebra</p>
                <ol>
                    <li>Identity law
                        <br>
                        In the Boolean Algebra, we have identity elements for both AND(.) and OR(+) operations. The
                        identity law states that in
                        Boolean algebra, we have such variables that, on operating with the AND and OR operations we get
                        the same result, i.e.
                        <ul>
                            <li>A + 0 = A</li>
                            <li>A.1 = A</li>
                        </ul>
                    </li>
                    <li>Commutative Law
                        <br>
                        Binary variables in Boolean Algebra follow the commutative law. This law states that operating
                        Boolean variables A and B
                        is similar to operating Boolean variables B and A. That is,
                        <ul>
                            <li>A. B = B. A</li>
                            <li>A + B = B + A</li>
                        </ul>
                    </li>
                    <li>Associative Law
                        <br>
                        Associative law states that the order of performing Boolean operator is illogical as their
                        result is always the same.
                        This can be understood as,
                        <ul>
                            <li>( A . B ) . C = A . ( B . C )</li>
                            <li>( A + B ) + C = A + ( B + C)</li>
                        </ul>
                    </li>
                    <li>Distributive Law
                        <br>
                        Boolean Variables also follow the distributive law, and the expression for the Distributive law
                        is given as:
                        <ul>
                            <li>A . ( B + C) = (A . B) + (A . C)</li>
                        </ul>
                    </li>
                    <li>Inversion Law
                        <br>
                        Inversion law is the unique law of Boolean algebra that states, the complement of the complement
                        of any number is the
                        number itself.
                        <ul>
                            <li>(A')' = A</li>
                        </ul>
                        Apart from these other laws are mentioned below:
                    </li>
                    <li>AND Law
                        <br>
                        AND law of the Boolean algebra uses AND operator and the AND law is,
                        <ul>
                            <li>A . 0 = 0
                            <li>A . 1 = A
                            <li>A . A = A
                        </ul>
                    </li>
                    <li>OR Law
                        <br>
                        OR law of the Boolean algebra uses OR operator and the OR law is,
                        <ul>
                            <li>A + 0 = A</li>
                            <li>A + 1 = 1</li>
                            <li>A + A = A</li>
                        </ul>
                    </li>
                    <li>Complement Law
                        <br>
                        The Complement Law states that a variable ORed with its complement is always 1, and a variable
                        ANDed with its complement
                        is always 0.
                        <ul>
                            <li>A + A' = 1</li>
                            <li>A . A' = 0</li>
                        </ul>
                    </li>
                    <li>Domination Law
                        <br>
                        The Domination Law states that any variable ORed with 1 will always be 1, and any variable ANDed
                        with 0 will always be
                        0.
                        <ul>
                            <li>A + 1 = 1</li>
                            <li>A . 0 = 0</li>
                        </ul>
                    </li>
                    <li>Double Negation Law
                        <br>
                        The Double Negation Law states that the complement of the complement of a variable is the
                        variable itself.
                        <ul>
                            <li>(A')' = A</li>
                        </ul>
                    </li>
                </ol>
            </section>
            <section class="layout">
                <h3 id="l5D">Digital Electronics and Logic Design</h3>
                <p>Digital electronics and logic designs are the foundation of modern computing systems, enabling the
                    operation of devices
                    from smartphones to advance computers.</p>
                <ul>
                    <li>Digital electronics focuses on circuits that process binary data (0s and 1s).</li>
                    <li>Logic design involves creating systems that perform specific functions using logical operations
                        like AND, OR, and NOT
                        gates.</li>
                </ul>
                <h4>Digital Electronics</h4>
                <p>Digital electronics is the branch of electronic systems that use discrete signals to represent and
                    process information.
                    This technology forms the foundation of most modern devices and systems.</p>
                <h4>Difference Between Analog and Digital Systems</h4>
                <p>The key difference between analog and digital systems lies in the way they represent information.</p>
                <ul>
                    <li>Analog Systems: These systems process continuous signals, meaning the information is represented
                        by a continuous wave.
                        For example, in analog audio signals, the sound is represented by varying voltages that
                        continuously change.</li>
                    <li>Digital Systems: In contrast, digital systems work with discrete signals, often represented as
                        binary. These signals are
                        not continuous, but rather consist of distinct, separate values. Digital systems are stable, and
                        immune to noise
                        interference compared to analog systems.</li>
                </ul>
                <h4>Logic Design</h4>
                <p>Logic design is the process of creating and implementing digital circuits using logic gates to
                    perform specific
                    functions. The goal of logic design is to convert a high-level problem into a series of logical
                    operations that can be
                    executed efficiently by digital circuits.</p>
                <p>Logic gates are the fundamental components of logic design. Each gate performs a specific logical
                    operation on one or
                    more binary inputs to produce a single output. The most common logic gates in Logic Design are:</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20250109162603702005/Introduction-of-Logic-Gates.webp">
                </div>
                <ul>
                    <li>AND Gate: Produces a '1' output only when all inputs are '1'; otherwise, the output is '0'.</li>
                    <li>OR Gate: Produces a '1' output when at least one input is '1'.</li>
                    <li>NOT Gate: Inverts the input; it outputs '1' when the input is '0', and '0' when the input is
                        '1'.</li>
                    <li>NAND Gate: The inverse of the AND gate. It outputs '0' only when all inputs are '1'.</li>
                    <li>NOR Gate: The inverse of the OR gate. It outputs '1' only when all inputs are '0'.</li>
                    <li>XOR Gate (Exclusive OR): Outputs '1' when the number of '1' inputs is odd.</li>
                    <li>XNOR Gate (Exclusive NOR): Outputs '1' when the number of '1' inputs is even.</li>
                </ul>
                <br>
                <p>These gates can be combined in various ways to create more complex digital circuits. The two main
                    types
                    of logic
                    circuits are combinational logic and sequential logic. Both types of logic circuits are essential in
                    building functional
                    digital systems. While combinational logic handles processing tasks, sequential logic is essential
                    for
                    systems needing
                    memory and state transitions.</p>
                <ul>
                    <li>Combinational Logic Circuits: In combinational logic, the output depends solely on the current
                        inputs.
                        These circuits do
                        not store any past information, meaning the output is only a function of the inputs at that
                        specific
                        moment. Examples
                        include adders, multiplexers, and encoders.</li>
                    <li>Sequential Logic Circuits: Unlike combinational logic, sequential circuits have memory elements
                        that
                        store previous
                        states. The output of these circuits depends not only on the current inputs but also on the
                        sequence of
                        inputs received
                        over time. Flip-flops and registers are examples of sequential logic circuits, which are used in
                        systems
                        like counters,
                        memory devices, and state machines.</li>
                </ul>
            </section>
            <section class="layout">
                <h3 id="l5E">Core Concepts and Applications</h3>
                <h4>Core Concepts</h4>
                <ul>
                    <li>Binary Number System: Digital electronics uses the binary system (0 and 1) for data
                        representation and
                        processing, with
                        conversions between binary, decimal, and hexadecimal essential for digital systems.</li>
                    <li>Logic Gates and Truth Tables: Logic gates perform operations on binary inputs, while truth
                        tables
                        represent all possible
                        input-output combinations, aiding in circuit design.</li>
                    <li>Boolean Algebra: Boolean algebra simplifies logical expressions and helps optimize digital
                        circuits
                        through operations
                        like AND, OR, and NOT.</li>
                    <li>Combinational Circuits: Combinational circuits depend solely on current inputs for producing
                        outputs
                        without memory.</li>
                    <li>Sequential Circuits: Sequential circuits store and process information based on both current and
                        past
                        inputs.</li>
                </ul>
                <h4>Applications</h4>
                <ul>
                    <li>Computing Systems: Enable fast arithmetic, data storage, and input/output operations.</li>
                    <li>Communication Systems: Power data transmission and signal processing in phones, routers, and
                        satellites.</li>
                    <li>Consumer Electronics: Ensure smooth operation in TVs, gaming consoles, and smart devices.</li>
                    <li>Automotive Systems: Control engines, safety, and navigation with reliable automation.</li>
                    <li>Medical Devices: Support precise monitoring, control, and diagnosis in healthcare tools.</li>
                    <li>Embedded Systems: Provide efficient control in appliances, robotics, and automation.</li>
                    <li>Industrial Automation: Ensure precision, flexibility, and smooth process control in
                        manufacturing.</li>
                </ul>
            </section>
            <section class="lessons"><!--LESSON 6-->
                <h2 id="l6">üì≤Lesson 6: Electronic Media</h2>
                <a href="https://www.slideshare.net/slideshow/electronic-media-16228343/16228343" class="source">
                    <h3>Source: Slideshare.net</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l6A">Introduction to Electronic Media</h3>
                <ul>
                    <li>The plural of medium, are means of communication.</li>
                    <li>Derived from the Latin word ‚Äúmedius‚Äù middle (‚Äúbetween‚Äù), the term refers to anything that
                        carries information between a
                        source and a receiver.</li>
                    <li>Is a mean of transmitting the message, thought opinion and view point.</li>
                    <li>Its purpose is to facilitate communication and learning.</li>
                </ul>
                <br>
                <h3>ELECTRONIC MEDIA</h3>
                <p>Electronic media is enjoying broader use every day with an increase in electronic devices being made.
                    The meaning of electronic media, as it is known in various spheres, has changed with the passage of
                    time.</p>
                <p>Electronic media exists today in many forms: radio, television, videotape, audiotape, telephone,
                    telegraph, computer
                    file, etc.</p>
                <br>
            </section>
            <section class="layout">
                <h3 id="l6B">History of Electronic Media</h3>
                <h4>HISTORY</h4>
                <ul>
                    <li><b>Telegraph, 1838</b>- Developed by Samuel Morse, the telegraph revolutionized long-distance
                        communication
                        by allowing messages to be transmitted through electrical signals using Morse code. For the
                        first time,
                        information could travel faster than any physical messenger.</li>
                    <li><b>Telephone, 1876</b>- Alexander Graham Bell's invention transformed the telegraph's dots and
                        dashes into
                        actual human voice transmission, making real-time conversation possible across distances.</li>
                    <li><b>Radio, 1895</b>- Guglielmo Marconi demonstrated wireless telegraphy, which eventually
                        evolved into
                        broadcast radio. This marked the beginning of mass media, as a single transmission could reach
                        countless
                        listeners simultaneously.</li>
                    <li><b>Television, 1927</b>- Philo Farnsworth successfully demonstrated the first fully electronic
                        television
                        system, combining audio and moving images to create an entirely new form of media consumption.
                    </li>
                    <li><b>Early Computer, 1942</b>- The first electronic general-purpose computers emerged during
                        World War II,
                        initially designed for military calculations but laying the groundwork for the digital age.</li>
                    <li><b>Photocopy Machine, 1946</b>- Chester Carlson's xerography process made document reproduction
                        quick and
                        accessible, transforming office work and information sharing.</li>
                    <li><b>Transistor, 1947</b>- This tiny semiconductor device replaced bulky vacuum tubes, enabling
                        electronics
                        to become smaller, more reliable, and energy-efficient‚Äîa critical step toward portable devices.
                    </li>
                    <li><b>Microcomputer, 1960's</b>- Smaller, more affordable computers began appearing, moving
                        computing power
                        out of massive institutional mainframes and closer to individual users.</li>
                    <li><b>Computer, between 1960's & 1980's</b>- Personal computers emerged and evolved rapidly during
                        this
                        period, eventually becoming household items and fundamentally changing how people work, learn,
                        and
                        communicate.</li>
                </ul>
                <p>Computer technology is advancing in every walk of life to the point which "change is occurring so
                    rapidly that there is no time to react."</p>
                <br>
                <p>Lancaster and Naisbitt proposed that we are approaching a <b>paperless society</b>, where it is
                    faster and less expensive to communicate through electronic channels: "It is becoming cheaper to
                    handle
                    words electronically than to handle them physically, to the point
                    where the physical mode is becoming too expensive for ordinary use."</p>
                <p>Implementing a computer-based system to facilitate scholarly communication has its own set of
                    concerns and issues. The Internet is an existing attempt at such a system. It offers users the
                    benefits of
                    access, file transfer, and electronic mail (which includes electronic journals) with remote systems
                    around the
                    world.</p>
            </section>
            <section class="layout">
                <h3 id="l6C">Principles of the Network & Types of Electronic Media</h3>
                <p>In his proposal for an ideal National Research and Education Network, Dr. E. Brownrigg suggests ten
                    principles be
                    adopted for such a scholarly system. It provides:</p>
                <ul>
                    <li>Protection of each user's first amendment rights.</li>
                    <li>The freedom of all users to publish onto the network.</li>
                    <li>A free market status for the network administration.</li>
                    <li>Remote access.</li>
                    <li>Privacy from government eavesdropping.</li>
                    <li>And recognition of intellectual property which includes copyright enforcement and royalty
                        distribution.</li>
                </ul>
                <br>
                <p>There are three traditional types of Electronic Media and a few Hybrids:</p>
                <ol>
                    <li>Television</li>
                    <li>Radio</li>
                    <li>Internet</li>
                    <li>Smart phones may have created a new media type</li>
                    <li>Electronic display advertising, electronic streaming billboards may also be a new hybrid</li>
                </ol>
                <ul>
                    <li>Internet, TV, Radio, arguably electronic Billboards might qualify.</li>
                    <li>Smart Phones are a play between Phone & internet so might pass for electronic media.</li>
                </ul>
                <br>
                <h4>Role of Electronic Media in Education Sector</h4>
                <p>Various multimedia and slide presentation (A primary electronic media source) is used.</p>
                <p>The sole aim of such presentations is to create certain expertise among students in the desired field
                    of education.</p>
                <p>The presentations are simple and easy to understand, the pictorial representation could enhance the
                    understanding level.</p>
            </section>
            <section class="layout">
                <h3 id="l6D">Advantage and Disadvantage of Electronic Media</h3>
                <h4>Advantages</h4>
                <ul>
                    <li><b>Immediacy</b>- Electronic media delivers information in real-time, eliminating the delays
                        associated
                        with print publication or physical distribution. Breaking news, live events, and urgent updates
                        reach
                        audiences within seconds of occurring.</li>
                    <li><b>Provides information and entertainment</b>- From educational documentaries to streaming
                        music,
                        electronic media serves both functional and recreational purposes, often blending the two
                        seamlessly.</li>
                    <li><b>Creates awareness among people</b>- Social issues, global events, and community concerns
                        gain visibility
                        through electronic platforms, enabling public discourse and collective action on important
                        matters.</li>
                    <li><b>It develops our thoughts and ideas</b>- Exposure to diverse perspectives, debates, and
                        creative content
                        through electronic media stimulates critical thinking and broadens intellectual horizons.</li>
                    <li><b>Keeps us in touch with what is happening in our society</b>- Local news broadcasts, social
                        media
                        updates, and online forums help citizens stay informed about political developments, cultural
                        events, and
                        community changes.</li>
                    <li><b>Made communication increasingly easier</b>- Email, instant messaging, video calls, and
                        social platforms
                        have simplified staying connected, reducing both the effort and cost of maintaining
                        relationships.</li>
                    <li><b>Connect diverse people from far and near geographical locations</b>- Electronic media
                        transcends
                        physical borders, enabling collaboration, friendship, and cultural exchange between individuals
                        who might
                        never meet in person.</li>
                </ul>
                <br>
                <br>
                <h4>Disadvantage</h4>
                <ul>
                    <li><b>Noise pollution</b>- The constant barrage of notifications, advertisements, and background
                        media creates
                        an overwhelming auditory environment that can cause stress and reduce concentration.</li>
                    <li><b>Decision Making</b>- The abundance of information and opinions available through electronic
                        media can
                        lead to analysis paralysis, making it harder for individuals to form confident decisions amidst
                        conflicting
                        sources.</li>
                    <li>Common diseases and complications brought by electronic media.
                        <ul>
                            <li><b>Eyesight</b>- Prolonged screen exposure can lead to digital eye strain,
                                characterized by dry
                                eyes, blurred vision, and headaches. The blue light emitted by screens may also disrupt
                                sleep
                                patterns.</li>
                            <li><b>Exposure to radiation</b>- Electronic devices emit low levels of electromagnetic
                                radiation.
                                While research on long-term effects continues, excessive exposure raises health
                                concerns,
                                particularly with devices held close to the body.</li>
                        </ul>
                    </li>
                </ul>
            </section>
            <section class="lessons"><!--LESSON 7-->
                <h2 id="l7">üõúLesson 7: The Internet</h2>
                <a href="https://www.geeksforgeeks.org/computer-science-fundamentals/introduction-to-internet/" class="source">
                    <h3>Source: Geeksforgeeks.org</h3>
                </a>
            </section>
            <section class="layout">
                <h3 id="l7A">Introduction to Internet</h3>
                <p>The Internet is a global network that connects millions of computers and devices, enabling people to
                    communicate, share
                    information, and access digital resources worldwide. It works like a vast highway system, where data
                    travels in small
                    packets between connected devices.</p>
                <ul>
                    <li>Facilitates instant communication and information exchange across the world.</li>
                    <li>Connects computers, smartphones, and servers through various wired and wireless networks.</li>
                    <li>Powers daily activities such as emailing, online learning, shopping, and entertainment.</li>
                </ul>
                <br>
                <h4>Internet vs. World Wide Web</h4>
                <p>Many people use the Internet and World Wide Web (WWW) interchangeably, but they are not the same.</p>
                <ul>
                    <li>The Internet is the infrastructure ‚Äî the physical network of cables, satellites, and routers.
                    </li>
                    <li>The World Wide Web is one of the services that runs on the Internet ‚Äî it‚Äôs where websites and
                        web pages exist, accessible through browsers like Chrome or Safari.</li>
                </ul>
                <br>
                <h4>The Public Revolution</h4>
                <p>In 1989‚Äì1991, Sir Tim Berners-Lee, a British scientist, invented the World Wide Web while working at
                    CERN. He created three key technologies:</p>
                <ol>
                    <li>HTML (HyperText Markup Language) ‚Äì for creating web pages</li>
                    <li>HTTP (HyperText Transfer Protocol) ‚Äì for communication between browsers and servers</li>
                    <li>URLs (Uniform Resource Locators) ‚Äì for addressing pages on the Web</li>
                </ol>
                <br>
                <p>By the mid-1990s, web browsers like Mosaic and Netscape Navigator made the Internet easy for everyone
                    to
                    use. The digital revolution had begun.</p>
            </section>
            <section class="layout">
                <h3 id="l7B">How the Internet Works</h3>
                <p>Internetworking describes the process and technologies that allow millions of computers and devices
                    to communicate and share data efficiently.</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20251029124734177711/modes_of_connection.webp">
                </div>
                <br>
                <h4>Protocols ‚Äì The Rules of the Road</h4>
                <p>All devices on the Internet follow a set of communication rules called protocols. The most important
                    ones are:</p>
                <ul>
                    <li>TCP (Transmission Control Protocol) ‚Äì Breaks data into smaller packets and ensures they arrive
                        safely.</li>
                    <li>IP (Internet Protocol) ‚Äì Assigns addresses and delivers packets to the correct destination.</li>
                    <li>HTTP/HTTPS ‚Äì Used for websites.</li>
                    <li>SMTP ‚Äì Used for sending emails.</li>
                </ul>
                <p>These protocols ensure smooth, reliable, and secure communication worldwide.</p>
                <br>
                <h4>IP Addresses ‚Äì The Street Address</h4>
                <p>Every device connected to the Internet has a unique IP Address (e.g., 192.168.1.1).
                    It‚Äôs like a home address that tells data packets where to go and where they came from. Modern
                    Internet
                    systems are transitioning from IPv4 to IPv6 to handle the massive number of connected devices.</p>
                <br>
                <h4>Data Packets ‚Äì The Small Boxes</h4>
                <p>When you send information ‚Äî like a photo or an email ‚Äî it‚Äôs divided into small chunks called packets.
                    Each packet travels through the Internet independently, sometimes by different routes, and they are
                    reassembled at
                    the destination into the original file.</p>
                <br>
                <h4>Internet Components</h4>
                <ul>
                    <li>Routers: Direct packets along the most efficient path.</li>
                    <li>Servers: Store and deliver data like websites, emails, and videos.</li>
                    <li>ISPs (Internet Service Providers): Companies like Airtel, Jio, AT&T, or Verizon that connect
                        users to the Internet.</li>
                    <li>DNS (Domain Name System): Translates website names (like google.com) into IP addresses.</li>
                </ul>
                <br>
            </section>
            <section class="layout">
                <h3 id="l7C">Applications of Internet</h3>
                <p>The versatility of the Internet means it touches virtually every part of modern life. It'sthe
                    platform that makes modern living possible.</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20251028111000926348/key_applications_of_internet.webp">
                </div>
                <br>
                <h4>A. Connect and Communicate</h4>
                <p>The Internet replaced slow communication with instant global interaction.</p>
                <ul>
                    <li>Email: The standard for formal and professional written messages and documents worldwide.</li>
                    <li>Instant Messaging & Video Calls: Services like WhatsApp, Zoom, and FaceTime allow for
                        real-time chat and virtual presence. You can talk to someone across the street or across the
                        globe just by tapping a screen.</li>
                </ul>
                <br>
                <h4>B. Find Information and Learn</h4>
                <p>The Internet is the largest collection of human knowledge ever assembled, making information
                    instantly available.</p>
                <ul>
                    <li>Search Engines: Tools like Google index billions of web pages to help you find exactly what
                        you need using simple keywords. They are the gateway to information.</li>
                    <li>Digital Education: The rise of online courses and digital libraries means you can access
                        high-quality educational materials and learn new skills anytime, anywhere.</li>
                </ul>
                <br>
                <h4>C. Shop and Manage Money</h4>
                <p>The Internet transformed how we buy goods and handle our finances.</p>
                <ul>
                    <li>E-commerce (Online Shopping): Sites like Amazon allow you to buy and sell products globally
                        from the
                        comfort of your
                        home, making retail a worldwide service.</li>
                    <li>Online Banking & Digital Payments: Apps and websites let you manage your accounts, pay
                        bills, and
                        transfer money
                        instantly and securely, reducing the need to visit a physical bank.</li>
                </ul>
                <br>
                <h4>D. Entertain and Socialize</h4>
                <p>For many, the Internet is primarily a source of entertainment and a way to connect socially.</p>
                <ul>
                    <li>Streaming Services: Netflix, YouTube, and Spotify offer on-demand entertainment. You can
                        watch movies, listen to music, or view clips instantly without needing to download large files.</li>
                    <li>Social Media & Gaming: Platforms like Instagram and online games connect users to
                        communities and provide shared experiences, allowing millions to interact and play together in digital spaces.</li>
                </ul>
                <br>
            </section>
            <section class="layout">
                <h3 id="l7D">Internet Safety and the Future</h3>
                <h4>Basic Security</h4>
                <p>As useful as the Internet is, it comes with risks such as viruses, hacking, identity theft, and misinformation. To stay safe:</p>
                <ul>
                    <li>Use strong, unique passwords.</li>
                    <li>Avoid suspicious links or emails (phishing scams).</li>
                    <li>Install antivirus software and enable firewalls.</li>
                    <li>Be careful with sharing personal information online.</li>
                </ul>
                <p>Digital awareness is essential to protect both privacy and data.</p>
                <br>
                <h4>Looking Ahead</h4>
                <p>The Internet continues to evolve with exciting innovations:</p>
                <ul>
                    <li>IoT (Internet of Things): Everyday devices like refrigerators and cars are now online.</li>
                    <li>5G and Fiber Optics: Providing ultra-fast Internet speeds.</li>
                    <li>Artificial Intelligence (AI): Making online systems smarter and more personalized.</li>
                    <li>Web 3.0: A decentralized, secure, and intelligent Internet future powered by blockchain and AI.</li>
                </ul>
                <br>
            </section>



            <section class="lessons"><!--LESSON 8-->
                <h2 id="l8">‚öñÔ∏èLesson 8: Ethics in Computing Industry</h2>
                <a href="https://www.acm.org/code-of-ethics" class="source">
                    <h3>Source: ACM.org</h3>
                </a>
                <a href="https://www.geeksforgeeks.org/computer-networks/intellectual-property-rights/" class="source">
                    <h3>Source:Geekforgeeks.org</h3>
                </a>
                <a href="https://en.wikibooks.org/wiki/The_Computer_Revolution/Digital_Counterfeiting#:~:text=In%20definition%20digital%20counterfeiting%20is,that%20allows%20to%20do%20so." class="source">
                    <h3>Source:Wikibooks.org</h3>
                </a>
            </section>

            <section class="layout">
                <h3 id="l8A">Introduction of Ethics in Computing Industry</h3>
                <p>Ethics in the computing industry involves moral principles guiding responsible tech use, covering privacy, security, intellectual property, fairness, and societal impact, ensuring professionals act honestly, respect users, protect data, and consider consequences of technologies like AI, addressing issues from hacking and piracy to data misuse and algorithmic bias. Professional codes (like ACM's) emphasize trustworthiness, transparency, avoiding harm, respecting creators, and prioritizing public good over personal gain.</p>
                <br>

                <h3>ACM Code of Ethics and Professional Conduct</h3>
                <p>Computing professionals' actions change the world. To act responsibly, they should reflect upon the wider impacts of their work, consistently supporting the public good. The ACM Code of Ethics and Professional Conduct ("the Code") expresses the conscience of the profession.
                    <br>
                    The Code is designed to inspire and guide the ethical conduct of all computing professionals, including current and aspiring practitioners, instructors, students, influencers, and anyone who uses computing technology in an impactful way. Additionally, the Code serves as a basis for remediation when violations occur. The Code includes principles formulated as statements of responsibility, based on the understanding that the public good is always the primary consideration. Each principle is supplemented by guidelines, which provide explanations to assist computing professionals in understanding and applying the principle.
                    <br>
                    Section 1 outlines fundamental ethical principles that form the basis for the remainder of the Code. Section 2 addresses additional, more specific considerations of professional responsibility. Section 3 guides individuals who have a leadership role, whether in the workplace or in a volunteer professional capacity. Commitment to ethical conduct is required of every ACM member, ACM SIG member, ACM award recipient, and ACM SIG award recipient. Principles involving compliance with the Code are given in Section 4.
                    <br>
                    The Code as a whole is concerned with how fundamental ethical principles apply to a computing professional's conduct. The Code is not an algorithm for solving ethical problems; rather it serves as a basis for ethical decision-making. When thinking through a particular issue, a computing professional may find that multiple principles should be taken into account, and that different principles will have different relevance to the issue. Questions related to these kinds of issues can best be answered by thoughtful consideration of the fundamental ethical principles, understanding that the public good is the paramount consideration. The entire computing profession benefits when the ethical decision-making process is accountable to and transparent to all stakeholders. Open discussions about ethical issues promote this accountability and transparency.
                </p>
                <br>
            </section>

            <section class="layout">
                <h3 id="l8B">Intellectual Property Rights</h3>
                <p>Intellectual property rights are the rights given to each and every person for the creation of new things according to their minds. IPR usually give the creator a complete right over the use of his/her creation for a certain period of time.</p>
                <br>
                <p>Intellectual property rights are the legal rights that cover the benefits given to individuals who are the owners and inventors of work and have created something unique with their intellectual creativity or capability. Every person related to areas such as literature, music, invention, etc., can be granted such rights, which can then be used in their business practices by them.</p>
                <br>
                <p>The creator/inventor gets complete rights against any misuse or use of work without his/her prior information. However, the rights are issued for a limited period of time to maintain equilibrium.</p>
                <br>

                <h4>What are Intellectual Properties?</h4>
                <ol>
                    <li>Industrial designs</li>
                    <li>Scientific discoveries</li>
                    <li>Protection against unfair competition</li>
                    <li>Literary, artistic, and scientific works</li>
                    <li>Inventions in all fields of human endeavor</li>
                    <li>Trademarks, service marks, commercial names, and designations</li>
                </ol>
                <br>
                <h4>Types of Intellectual Property Rights:</h4>
                <p>Intellectual Property Rights can be classified into four types:</p>
                <div class="center-image">
                    <img src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190409115734/5555.jpg">
                </div>
                <ol>
                    <li>Copyright: Copyright is a term that describes ownership or control of the rights to the use and distribution of certain works of creative expression, including books, videos, movies, music, and computer programs.</li>
                    <li>Patent: A patent gives its owner the right to exclude others from making, using, selling, and importing an invention for a limited period of time. The patent rights are granted in exchange for enabling public disclosure of the invention.</li>
                    <li>Trademark: A Trademark is a Graphical representation that is used to distinguish the goods and services of one party from those of others. A Trademark may consist of a letter, number, word, phrase, logo, graphic, shape, smell, sound, or combination of these things.</li>
                    <li>Trade Secrets: Trade secret describes about the general formula of any product and the key behind any organization's progress. It also includes various firms' different secret formulas for the same products which differ in quality.</li>
                </ol>
                <br>
                <h4>Advantages of Intellectual Property Rights:</h4>
                <p>The advantages of intellectual property rights are as follows:</p>
                <ul>
                    <li>IPR yields exclusive rights to the creators or inventors.</li>
                    <li>It encourages individuals to distribute and share information and data instead of keeping it confidential.</li>
                    <li>It provides legal defense and offers the creators the incentive of their work.</li>
                    <li>It helps in social and financial development.</li>
                    <li>It inspires people to create new things without fear of intellectual theft.</li>
                </ul>
                <br>
            </section>

            <section class="layout">
                <h3 id="l8C">Digital Counterfeiting</h3>
                <p>In definition digital counterfeiting is the use of computers or digital equipment to make counterfeit copies of printed resources. The major example of counterfeits is currency which according to the U.S. Secret Service around 60% of currency made counterfeit is done so digitally. Other counterfeit items also include business checks, collectibles, fake identifications, and credit cards. The practice of counterfeiting is illegal in the United States and offenders could be sentenced to 15 years per offense. The majority of counterfeit currency are produced by gangs, organized crime, and terrorist organizations but has also been seen done so by college students and even high school students. Although easily detectable counterfeit currency has had more ease of creating due to more and more digital technology that allows to do so.</p>
                <br>
                <p>In order to prevent currency counterfeiting, the Government has been implementing measures such as changing the currency design every 7 to 10 years. With each new edition they are incorporating additional security features (watermarks, microprinting)which make it hard to duplicate the bills and can be easily seen when holding the bills up to the light. Also, in order to make it easier to track the source of the counterfeit item, the digital imaging equipment(copiers, scanners)are equipped with technologies such as printing invisible code that make tracking possible.Cannon has revealed to be using such technologies since 1992. Source - Understanding Computers: Today and Tomorrow, 13th Edition</p>
                <br>
                <h4>Digital Watermark</h4>
                <p>The use of digital watermarks is incredibly popular and most often people have no idea when something actually has a digital watermark. Digital watermarks are used to identify whether or not a document has been tampered with, protect sensitive material from unauthorized editing and to deter things like counterfeiting and piracy. The process of digital watermarking involves embedding digital information or identifiers into audio, video and printed materials. The digital watermark, while undetectable to people can easily be identified and analyzed by computers.</p>
                <br>
                <h4>Security Thread</h4>
                <p>One digital counterfeiting prevention tool is a security thread. A security thread is a plastic strip that is embedded in U.S. currency. This strip can only be seen when it is held up to the light or when placed under an ultraviolet light. When you make the strip visible, it shows the letters USA followed by a number. The number is the value of the bill. For example a one dollar bill will have "USA 1" printed on the security thread. This feature makes currency hard to duplicate but not impossible. Some counterfeits have been known to have a thin grey line printed on the end of the thread or a varnish at the end.</p>
                <br>
            </section>

        </main>
    </div>
    <!--Footer Section-->
    <footer>
        <p>&copy; 2026 Liane Raizel N. Roga Portfolio</p>
    </footer>
    <script src="script.js"></script>
</body>

</html>
